{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCPG Test Notebook\n",
    "\n",
    "This notebook facilitates testing the the core functionality of the FCPG tools. This steps through providing input data, converting ESRI flow directions to TauDEM flow direction, resampling and reprojecting input data, generating upstream FCPGs, creating a dictionary to cascade values from upstream to downstream hydrologic units, updating downstream parameter grids, accumulating updated grids, and making FCPGs corrected for an upstream area. The last section verifies the handling of no data values if that is desired by the user.\n",
    "\n",
    "This notebook reads data from `./test_data` and writes data to `./test_output`. `./test_output` can be discarded after testing is complete.\n",
    "\n",
    "Input and output grids can be examined in either ArcGIS or QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCPGtools version 1.0.9 loaded from C:\\Users\\xrnogueira\\Documents\\FCPGtools\\FCPGtools\n"
     ]
    }
   ],
   "source": [
    "import FCPGtools as fc\n",
    "import os\n",
    "import rasterio as rs\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Verbose output\n",
    "verbose = True\n",
    "\n",
    "\n",
    "def plot(fl, cmap='Blues'):\n",
    "    \"\"\"\n",
    "    Helper plotter function.\n",
    "    \"\"\"\n",
    "    src = rs.open(fl)\n",
    "    tmp = src.read(1)\n",
    "    try:\n",
    "        tmp[tmp == src.nodata] = np.NaN\n",
    "    except:\n",
    "        pass\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(tmp, cmap = cmap)\n",
    "\n",
    "\n",
    "print('FCPGtools version %s loaded from %s'%(fc.__version__,fc.__path__[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upstream area FDR grid\n",
    "upstreamFDR = os.path.join('.', 'test_data', 'validation_upstream_fdr.tif')\n",
    "\n",
    "# downstream area FDR grid\n",
    "downstreamFDR = os.path.join('.', 'test_data', 'validation_downstream_fdr.tif')\n",
    "\n",
    "# upstream WBD subset to test cascading parameters\n",
    "upstreamWBD = gpd.read_file(os.path.join('.', 'test_data/upstream_wbd.shp'))\n",
    "\n",
    "# parameter datasets\n",
    "P = os.path.join('.', 'test_data', 'validation_daymet_an_P_2017.tif')  # daymet annual P for 2017\n",
    "LC = os.path.join('.', 'test_data', 'NALCMS_2015.tif')  # North America Land Cover 2015\n",
    "\n",
    "testFolder = os.path.join('.', 'test_output')  # folder to store outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xrnogueira\\Miniconda3\\envs\\fcpgtools\\lib\\site-packages\\pyproj\\crs\\crs.py:130: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "# reproject the WBD to the grid CRS\n",
    "tmp = rs.open(upstreamFDR)\n",
    "dstCRS = tmp.crs.to_proj4()\n",
    "\n",
    "upstreamWBD.to_crs(crs=dstCRS, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test output location if it doesn't exist, this directory can be deleted later\n",
    "if os.path.exists(testFolder) is False:\n",
    "    os.mkdir(testFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert ESRI FDR to TauDEM FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output paths\n",
    "upstreamFDRTau = os.path.join(testFolder, 'upstreamFDRtau.tif')\n",
    "downstreamFDRTau = os.path.join(testFolder, 'downstreamFDRtau.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclassifying Flow Directions...\n",
      "TauDEM drainage direction written to: .\\test_output\\upstreamFDRtau.tif\n",
      "Reclassifying Flow Directions...\n",
      "TauDEM drainage direction written to: .\\test_output\\downstreamFDRtau.tif\n"
     ]
    }
   ],
   "source": [
    "# reclassify ESRI drainage directions to TauDEM\n",
    "fc.tauDrainDir(upstreamFDR, upstreamFDRTau, verbose=verbose)\n",
    "fc.tauDrainDir(downstreamFDR, downstreamFDRTau, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample Daymet and Land Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output paths\n",
    "Pupstream = os.path.join(testFolder, 'Pup.tif')\n",
    "Pdownstream = os.path.join(testFolder, 'Pdwn.tif')\n",
    "LCupstream = os.path.join(testFolder, 'LCup.tif')\n",
    "LCdownstream = os.path.join(testFolder, 'LCdwn.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Direction Proj4: \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\"\n",
      "Parameter Proj4:+proj=lcc +lat_0=42.5 +lon_0=-100 +lat_1=25 +lat_2=60 +x_0=0 +y_0=0 +a=6378137 +rf=298.25723 +units=m +no_defs=True\n",
      "Flow Direction Xsize:30.0\n",
      "Parameter Xsize:1000.0\n",
      "FDR Lower Right Corner: -1354064.9999999995, 1635194.9999999963\n",
      "FDR Upper Left Corner: -1384004.9999999995, 1666364.9999999963\n",
      "Param Lower Right Corner: -971750.0, -542500.0\n",
      "Param Upper Left: -1002750.0, -511500.0\n",
      "Resampling and Reprojecting Parameter Raster...\n",
      "gdalwarp -overwrite -tr 30.0 30.0 -t_srs \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\" -te -1384004.9999999995 1635194.9999999963 -1354064.9999999995 1666364.9999999963 -co \"PROFILE=GeoTIFF\" -co \"TILED=YES\" -co \"SPARSE_OK=TRUE\" -co \"COMPRESS=LZW\" -co \"ZLEVEL=9\" -co \"NUM_THREADS=1\" -co \"BIGTIFF=IF_SAFER\" -r bilinear -dstnodata -999.0 -ot Float32 .\\test_data\\validation_daymet_an_P_2017.tif .\\test_output\\Pup.tif\n",
      "Flow Direction Proj4: \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\"\n",
      "Parameter Proj4:+proj=lcc +lat_0=42.5 +lon_0=-100 +lat_1=25 +lat_2=60 +x_0=0 +y_0=0 +a=6378137 +rf=298.25723 +units=m +no_defs=True\n",
      "Flow Direction Xsize:30.0\n",
      "Parameter Xsize:1000.0\n",
      "FDR Lower Right Corner: -1369395.0000000007, 1637025.0\n",
      "FDR Upper Left Corner: -1384635.0000000007, 1653435.0\n",
      "Param Lower Right Corner: -971750.0, -542500.0\n",
      "Param Upper Left: -1002750.0, -511500.0\n",
      "Resampling and Reprojecting Parameter Raster...\n",
      "gdalwarp -overwrite -tr 30.0 30.0 -t_srs \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\" -te -1384635.0000000007 1637025.0 -1369395.0000000007 1653435.0 -co \"PROFILE=GeoTIFF\" -co \"TILED=YES\" -co \"SPARSE_OK=TRUE\" -co \"COMPRESS=LZW\" -co \"ZLEVEL=9\" -co \"NUM_THREADS=1\" -co \"BIGTIFF=IF_SAFER\" -r bilinear -dstnodata -999.0 -ot Float32 .\\test_data\\validation_daymet_an_P_2017.tif .\\test_output\\Pdwn.tif\n",
      "Flow Direction Proj4: \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\"\n",
      "Parameter Proj4:+proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs=True\n",
      "Flow Direction Xsize:30.0\n",
      "Parameter Xsize:30.0\n",
      "FDR Lower Right Corner: -1369395.0000000007, 1637025.0\n",
      "FDR Upper Left Corner: -1384635.0000000007, 1653435.0\n",
      "Param Lower Right Corner: -1015590.0, -844300.0\n",
      "Param Upper Left: -1044870.0, -813880.0\n",
      "Resampling and Reprojecting Parameter Raster...\n",
      "gdalwarp -overwrite -tr 30.0 30.0 -t_srs \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\" -te -1384635.0000000007 1637025.0 -1369395.0000000007 1653435.0 -co \"PROFILE=GeoTIFF\" -co \"TILED=YES\" -co \"SPARSE_OK=TRUE\" -co \"COMPRESS=LZW\" -co \"ZLEVEL=9\" -co \"NUM_THREADS=1\" -co \"BIGTIFF=IF_SAFER\" -r near -dstnodata None -ot Byte .\\test_data\\NALCMS_2015.tif .\\test_output\\LCdwn.tif\n",
      "Flow Direction Proj4: \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\"\n",
      "Parameter Proj4:+proj=laea +lat_0=45 +lon_0=-100 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs=True\n",
      "Flow Direction Xsize:30.0\n",
      "Parameter Xsize:30.0\n",
      "FDR Lower Right Corner: -1354064.9999999995, 1635194.9999999963\n",
      "FDR Upper Left Corner: -1384004.9999999995, 1666364.9999999963\n",
      "Param Lower Right Corner: -1015590.0, -844300.0\n",
      "Param Upper Left: -1044870.0, -813880.0\n",
      "Resampling and Reprojecting Parameter Raster...\n",
      "gdalwarp -overwrite -tr 30.0 30.0 -t_srs \"+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs\" -te -1384004.9999999995 1635194.9999999963 -1354064.9999999995 1666364.9999999963 -co \"PROFILE=GeoTIFF\" -co \"TILED=YES\" -co \"SPARSE_OK=TRUE\" -co \"COMPRESS=LZW\" -co \"ZLEVEL=9\" -co \"NUM_THREADS=1\" -co \"BIGTIFF=IF_SAFER\" -r near -dstnodata None -ot Byte .\\test_data\\NALCMS_2015.tif .\\test_output\\LCup.tif\n"
     ]
    }
   ],
   "source": [
    "# resample and crop daymet (upstream then downstream)\n",
    "fc.resampleParam(P, upstreamFDRTau, Pupstream, forceProj=True, verbose=verbose)\n",
    "fc.resampleParam(P, downstreamFDRTau, Pdownstream, forceProj=True, verbose=verbose)\n",
    "\n",
    "# resanoke LC raster (upstream then downstream)\n",
    "fc.resampleParam(LC, upstreamFDRTau, LCupstream, forceProj=True,\n",
    "                 verbose=verbose, resampleMethod='near')\n",
    "fc.resampleParam(LC, downstreamFDRTau, LCdownstream, forceProj=True,\n",
    "                 verbose=verbose, resampleMethod='near')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize Land Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating binaries for .\\test_output\\LCup.tif\n",
      "Creating binaries for .\\test_output\\LCdwn.tif\n"
     ]
    }
   ],
   "source": [
    "usLCbinary = fc.cat2bin(LCupstream, testFolder, verbose=verbose)\n",
    "dsLCbinary = fc.cat2bin(LCdownstream, testFolder, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulate the Upstream Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating Data...\n",
      "mpiexec -n 4 aread8 -p .\\test_output\\upstreamFDRtau.tif -ad8 .\\test_output\\upstreamFAC.tif -nc\n"
     ]
    }
   ],
   "source": [
    "# create path for, and the output for, a FAC grid\n",
    "upstreamFAC = os.path.join(testFolder, 'upstreamFAC.tif')\n",
    "\n",
    "fc.tauFlowAccum(upstreamFDRTau, upstreamFAC, cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": ".\\test_output\\upstreamFAC.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mrasterio\\_base.pyx:302\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\_base.pyx:213\u001b[0m, in \u001b[0;36mrasterio._base.open_dataset\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\_err.pyx:217\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: .\\test_output\\upstreamFAC.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupstreamFAC\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(fl, cmap)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(fl, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;66;03m# define a helper plotting function\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m     src \u001b[38;5;241m=\u001b[39m \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     tmp \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\fcpgtools\\lib\\site-packages\\rasterio\\env.py:442\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\fcpgtools\\lib\\site-packages\\rasterio\\__init__.py:277\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m path \u001b[38;5;241m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 277\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m DatasetReader(path, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    279\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m get_writer_for_path(path, driver\u001b[38;5;241m=\u001b[39mdriver)(\n\u001b[0;32m    280\u001b[0m         path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    281\u001b[0m     )\n",
      "File \u001b[1;32mrasterio\\_base.pyx:304\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRasterioIOError\u001b[0m: .\\test_output\\upstreamFAC.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "plot(upstreamFAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of Multiple Pour Points\n",
    "\n",
    "The following is a demonstration of the workflow for HUC4 geospatial tiles (NHD High-Res). The update dictionary produced here is not used after this Section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstreamWBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pourBasins = fc.makePourBasins(upstreamWBD, '1407', '1501')\n",
    "pourPts = fc.findPourPoints(pourBasins, upstreamFAC, upstreamFDRTau, plotBasins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pourPts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an initial dictionary for the region 14 to 15 cascade\n",
    "updateDictFl = os.path.join(testFolder, 'HUC1407_update.json')\n",
    "upHUC = '1407'\n",
    "\n",
    "# expand the pour points\n",
    "x, y, w = zip(*pourPts)\n",
    "ud = fc.createUpdateDict(x, y, w, upHUC, updateDictFl, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud  # there are two pour points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Pour Point to Downstream Area\n",
    "Here we find the single pour point between region 14 and region 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# locate max FAC value\n",
    "x, y, d, w = fc.findLastFACFD(upstreamFAC, fl=upstreamFAC)\n",
    "\n",
    "# Get flow direction of above point\n",
    "x, y, f, w = fc.findLastFACFD(upstreamFAC, fl=upstreamFDRTau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an initial dictionary for the region 14 to 15 cascade\n",
    "updateDictFl = os.path.join(testFolder, 'HUC14_update.json')\n",
    "upHUC = '14'\n",
    "ud = fc.createUpdateDict([x], [y], [d], upHUC, updateDictFl, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCPG Upstream Daymet and Land Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the Daymet path to the land cover binary grids\n",
    "usLCbinary.append(Pupstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumParams = fc.accumulateParam_batch(usLCbinary, upstreamFDRTau, testFolder,\n",
    "                                       cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_cpgs = fc.make_fcpg_batch(accumParams, upstreamFAC, testFolder, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Update Dictionary with FCPG Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update the dictionary with values from the upstream accumulated parameters, this should probably be a v2 function...\n",
    "for fl in accumParams:  # iterate through the accumulated parameters\n",
    "    print(fl)\n",
    "    # Parse the file names into variable names...\n",
    "    varname = fl.split('/')[-1].split('up')[0]\n",
    "    if varname == 'LC':\n",
    "        mod = fl.split('/')[-1].split('up')[-1].split('accum')[0]\n",
    "        var = varname+mod\n",
    "    else:\n",
    "        var = varname\n",
    "\n",
    "    # Query accumualted raster for values\n",
    "    val = str(fc.queryPoint(x, y, fl))\n",
    "    ud = fc.updateDict(updateDictFl, '14', var, [val])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade to Downstream Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downstreamFACadj = os.path.join(testFolder, 'downstreamFACadj.tif')\n",
    "downstreamFACweight = os.path.join(testFolder, 'downstreamFACweight.tif')\n",
    "fc.adjustFAC(downstreamFDRTau, downstreamFACweight, updateDictFl, downstreamFDRTau,\n",
    "             downstreamFACadj, cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsLCbinary.append(Pdownstream) #add the precip into the downstream land cover files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create updated, unaccumulated parameter grids for the downstream region\n",
    "adjDSparams = []\n",
    "\n",
    "# iterate through the accumulated parameters\n",
    "for fl, inGrid in zip(accumParams, dsLCbinary):\n",
    "    # Parse the file names into variable names...\n",
    "    varname = fl.split('/')[-1].split('up')[0]\n",
    "    if varname == 'LC':\n",
    "        mod = fl.split('/')[-1].split('up')[-1].split('accum')[0]\n",
    "        var = varname+mod\n",
    "    else:\n",
    "        var = varname\n",
    "\n",
    "    outfl = inGrid.split('.tif')[0]+'adj.tif'\n",
    "\n",
    "    fc.adjustParam(var, inGrid, updateDictFl, outfl, verbose=verbose)\n",
    "    adjDSparams.append(outfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate the downstream parameter grids\n",
    "DSaccum = fc.accumulateParam_batch(adjDSparams, downstreamFDRTau, testFolder,\n",
    "                                   cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumulate the downstream area\n",
    "dsFCPG = fc.make_fcpg_batch(DSaccum, downstreamFACadj, testFolder, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert NoData values into Daymet and Verify FCPG NoData Behavior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rs.open(upstreamFDR) as src:\n",
    "    fdr = src.read(1)\n",
    "    fdr[fdr == src.nodata] = 0\n",
    "    fdr[fdr != 0] = 1\n",
    "    mask = fdr.astype(np.uint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make row,col vectors of where to insert nodata values\n",
    "size = 1000  # number of no data values to insert\n",
    "\n",
    "# get locations of all points within the watershed\n",
    "idCol, idRow = np.where(mask == 1)\n",
    "cols = np.random.choice(idCol, size=size, replace=False)\n",
    "rows = np.random.choice(idRow, size=size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file name\n",
    "PupstreamNoData = os.path.join(testFolder, 'PupNoData.tif')\n",
    "\n",
    "# open source\n",
    "with rs.open(Pupstream) as src:\n",
    "    meta = src.meta\n",
    "    noData = src.nodata\n",
    "    P = src.read(1)\n",
    "\n",
    "P[cols, rows] = noData  # insert nodata values\n",
    "\n",
    "# write out updated P grid\n",
    "with rs.open(PupstreamNoData, 'w', **meta) as dst:\n",
    "    dst.write(P, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumualte the P raster with no data values added and produce the noData grids\n",
    "\n",
    "accumRast = os.path.join(testFolder, 'PupNoData_accum.tif')\n",
    "outNoDataAccum = os.path.join(testFolder, 'PupNoData_accumNoData.tif')\n",
    "outNoData = os.path.join(testFolder, 'PupNodataRast.tif')\n",
    "outNoDataZero = os.path.join(testFolder, 'PupNoDataZero.tif')\n",
    "\n",
    "fc.accumulateParam(PupstreamNoData, upstreamFDRTau, accumRast,\n",
    "                   outNoDataRast = outNoData, outNoDataAccum=outNoDataAccum,\n",
    "                   zeroNoDataRast = outNoDataZero, cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a FCPG accounting for noData\n",
    "outRast = os.path.join(testFolder, 'Pup_FCPG_noData.tif')\n",
    "\n",
    "fc.make_fcpg(accumRast, upstreamFAC, outRast, noDataRast=outNoDataAccum, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decay FCPG\n",
    "\n",
    "Produce a FCPG where values are decayed based on their distance to a stream, this can be useful for producing FCPGs with more localized values rather than basin-average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D-infinity flow direction raster\n",
    "upstreamFDRTauDinf = os.path.join(testFolder, 'upstreamFDRDinf.tif')\n",
    "\n",
    "# convert D8 flow directions to D-inf flow directions\n",
    "fc.d8todinfinity(upstreamFDRTau, upstreamFDRTauDinf, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streamDistRast = os.path.join(testFolder, 'upstreamDist2Stream.tif')  # distance to stream raster\n",
    "streamRast = os.path.join(testFolder, 'upstreamSTR900.tif')  # stream raster\n",
    "fc.makeStreams(upstreamFAC, streamRast, verbose = verbose)\n",
    "\n",
    "# compute distance to streams, use 900 cells as accumulation threshold\n",
    "fc.dist2stream(upstreamFDRTau, upstreamFAC, 900, streamDistRast, cores = 4, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decayRast = os.path.join(testFolder, 'upstreamDecay.tif')\n",
    "k = 4  # decay coefficient\n",
    "fc.makeDecayGrid(streamDistRast, k, decayRast, verbose = verbose)\n",
    "plot(decayRast, cmap = 'Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decayFAC = os.path.join(testFolder, 'decayAccum.tif')  # decay accumulation grid\n",
    "decayParam = os.path.join(testFolder, 'decayP.tif')  # decay parameter accumulation grid\n",
    "\n",
    "# perform the parameter decay accumulation\n",
    "fc.decayAccum(upstreamFDRTauDinf, decayRast, decayParam,  \n",
    "              paramRast = Pupstream, cores = 4, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decayFCPG = os.path.join(testFolder, 'decayFCPG.tif')\n",
    "\n",
    "# Mask out pixels not on streamlines\n",
    "fc.maskStreams(decayParam, streamRast, decayFCPG, verbose = verbose)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
