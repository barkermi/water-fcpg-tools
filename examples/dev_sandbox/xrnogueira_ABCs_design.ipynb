{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3afad325-74f5-4377-9a51-414b4cb0177f",
   "metadata": {},
   "source": [
    "FCPG Tools Refactoring - Abstract Base Classes (ABC) v1\n",
    "========================================================\n",
    "**By:** @xaviernogueira\n",
    "\n",
    "**Design philosphy:**\n",
    "* Single responsibility - all functions should do a single task. Their functionality should not be repeated in other functions.\n",
    "* Object oriented - Python class objects will be used to produce cleaner looking code as well as enable storage of relevant parameters between steps. Rasters will be stored in memory rather than being constantly written to disk.\n",
    "* Modular - while the existing installation of FCPGTools pulls all tools in as functions, in version 2.0.0 there will be multiple modules/classes containing functions. This allows for lighter weight imports avoiding GDAL and TauDEM dependencies. This also allows for expirementation with new geoprocessing engines (i.e., [`pysheds`](https://github.com/mdbartos/pysheds)).\n",
    "* Modern Python formatting - all functionality will be written following the [PEP8](https://peps.python.org/pep-0008/) style guide to match modern programming conventions.\n",
    "\n",
    "**New features:**\n",
    "* Multi-band support - since most hydrology relevant parameter grids are multi-band (with bands representing the time axis), all functions should work effectively the same regardless of how many bands are present. This can be handled by switching to an [`xarray`](https://docs.xarray.dev/en/stable/) tech stack.\n",
    "* Pipeline facilitation - there should be oppurtunities to automate large parts of the work flow with no intervention. This will require certain function parameters to be pulled from raster metadata. Additionally, this requires replacing the existing design where rasters are read/write by [rasterio](https://rasterio.readthedocs.io/en/latest/) to a design **where raster objects can be held in memory between steps.**\n",
    "* Performance optimization as a default - while some functions give the user an oppurtunity to input the # of cores they want to use on their computer, this optional parameter will likely not get used by more novice end users. Therefore I propose a workflow where a simple boolean `param:optimize` can control whether multi-processing is used. If `optimize=True` the program should automatically be able to identify the # of cores to use and allocate computation resources accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1496bb8a-258b-4878-9f02-0ae1a2edae8f",
   "metadata": {},
   "source": [
    "# GeoSpatial/IO Engine Abstract Base Classes\n",
    "\n",
    "**Description:** The idea here is that there is a set of funcitons that are deemed core/lite. **These functions are made concrete in different tech-stacks**, inhereting from the Abstract Base Class (think ODM2 API implementation). The `GeoSpatialEngineFull` ABC inehretes from the lite ABC, and is made concrete (i.e., inhereted from) using additional engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21f56f29-d274-4d24-951d-d5ff7859cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dfa64-2ab6-48ad-9aae-f3ee2a84e33b",
   "metadata": {},
   "source": [
    "## GeoSpatialEngineLite - ABC\n",
    "\n",
    "* **Prepare Flow Direction Raster:**\n",
    "    * `d8_fdr()`: makes a D8 Flow Direction Raster (FDR) from a DEM raster.\n",
    "    * `convert_d8()`: converts D8 FDR encodings (i.e., ESRI -> TauDEM).\n",
    "* **Prepare parameter grids:**\n",
    "    * `clip()`: rectangularly clip a raster to match the spatial extent of another raster (or custom bounding box coordinates or shapefile). \n",
    "    * `resample()`: resample a raster to match the cell size of another raster (or a custom cell size). \n",
    "    * `reproject()`: reproject a raster to match another raster (or a custom CRS).\n",
    "    * `mask()`:\n",
    "    * `binarize_categorical_rasters()`: one-hot-encode a categorical parameter raster so that each unique category is represented w/ cell=1 in it's band in a multi-dimensional DataArray.\n",
    "* **Flow Accumulation Raster (FAC) related functions:**\n",
    "    * `fac_from_fdr()`: create a FAC from a FDR.\n",
    "    * `parameter_accumulation`: create a parameter grid accumulation raster (can be multi-dimensional along a time axis). \n",
    "    * `find_pour_points()`: find basin pour points (outflow cells) and their accumulation values (cell or paramater).\n",
    "    * Note: We need to be able to create both FAC and parameter accumulation rasters **given boundary conditions (i.e., upstream basin pour points)** -> this is done by first using update_cell_values() before creating the FAC and in V2 could simply be a parameter of `parameter_accumulation()` and `fac_from_fdr()`.\n",
    "* **Flow Conditioned Parameter Grid (FCPG):**\n",
    "    * `create_fcpg()`: create a multi-dimensional FCPG raster for a parameter grid stack.\n",
    "* **Other raster/utility functions:**\n",
    "    * `sample_raster()`: gets a cell value from a raster by specifying coordinates. \n",
    "    * `get_min_cell()`: gets the coordinates and value of a raster's minimum cell value. \n",
    "    * `get_max_cell()`: gets the coordinates and value of a raster's maximum cell value. \n",
    "    * `update_cell_values()`: updates the value of a raster cell specified by coordinates.\n",
    "    * `get_shp_bbox()`: gets the spatial extent of a shapefile as a bounding box list.\n",
    "    * `get_raster_bbox()`: gets the spatial extent of a raster as a bounding box list.\n",
    "    * `verify_extent()`: check if coordinates are contained by a raster's extent.\n",
    "\n",
    "**Notes:** \n",
    "* For `d8_fdr()` I am making `xarray.DataArray` returns default behavior, although one can save the intermediate files if they decide to.\n",
    "* If we go past TauDEM we should support (and have some automatic way to verify) D8 cell value meanings?\n",
    "* Reading and writing rasters files should *ideally* be done in a separate IOEngine ABC. An issue we may run into here is that some engines (i.e., GDAL) work directly with paths via cmd line, therefore one would not need a xarray -> read/write functionality necessarily. **(bring up in a meeting)**.\n",
    "* `param:in_raster` is used when the input raster is altered in some way, while `param:raster` is used when there is no edits made to the file (i.e., just getting info).\n",
    "* As of now, pour point boudnary conditions will be stored in a dictionary - `{(lat:float, lon:float): updated_cell_value:int}`.\n",
    "    * **Workflow:** First mask by downstream basin, and then add the upstream pour points accumulation values to the masked raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868a01b-5a30-4781-8ec0-db5c67be6d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSpatialEngineLite(abc.ABC):\n",
    "    \"\"\"Abstract Base Class for the core FCPGTools functions that can be ran w/o TauDEM.\"\"\"\n",
    "\n",
    "    #  Prepare flow direction raster (FDR)\n",
    "    @abc.abstractmethod\n",
    "    def d8_fdr(dem: Union[xr.DataArray, str], out_path: str = None,\n",
    "               out_format: str = 'TauDEM') -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Creates a flow direction raster from a DEM. Can either save the raster or keep in memory.\n",
    "        :param dem: (xr.DataArray or str raster path) the DEM from which to make the FDR.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param out_format: (str, default=TauDEM) type of D8 flow direction encoding for output.\n",
    "        :returns: the FDR as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def convert_d8(d8_fdr: Union[xr.DataArray, str], out_path: str = None,\n",
    "                   in_format: str = 'ESRI', out_format: str = 'TauDEM') -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Recodes a D8 FDR between different formats (default is ESRI -> TauDEM).\n",
    "        :param d8_fdr: (xr.DataArray or str raster path) a D8 Flow Direction Raster (dtype=Int).\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param in_format: (str, default=TauDEM) input rasters D8 flow direction encoding type.\n",
    "        :param out_format: (str, default=TauDEM) type of D8 flow direction encoding for output.\n",
    "        :returns: the recoded D8 FDR as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def find_cell_downstream(d8_fdr: Union[xr.DataArray, str], coords: tuple) -> tuple:\n",
    "        \"\"\"\n",
    "        Uses a D8 FDR to find the cell center coordinates downstream from any cell (specified\n",
    "        Note: this replaces py:func:FindDownstreamCellTauDir(d, x, y, w) in the V1.1 repo.\n",
    "        :param d8_fdr: (xr.DataArray or str raster path) a D8 Flow Direction Raster (dtype=Int).\n",
    "        :param coords: (tuple) the input (lat:float, lon:float) to find the next cell downstream from.\n",
    "        :returns: (tuple) an output (lat:float, lon:float) representing the cell center coorindates\n",
    "            downstream from the cell defined via :param:coords.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # prepare parameter grid rasters\n",
    "    @abc.abstractmethod\n",
    "    def clip(in_raster: Union[xr.DataArray, str], match_raster: Union[xr.DataArray, str] = None,\n",
    "             out_path: str = None, custom_shp: Union[str, gpd.GeoDataFrame] = None,\n",
    "             custom_bbox: list = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Clips a raster to the rectangular extent (aka bounding box) of another raster (or shapefile).\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param match_raster: (xr.DataArray or str raster path) if defined, in_raster is\n",
    "            clipped to match the extent of match_raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param custom_shp: (str path or GeoDataFame, default=None) a shapefile that is used to define\n",
    "            the output extent if match_raster == None.\n",
    "        :param custom_bbox: (list, default=None) a list with bounding box coordinates that define the output\n",
    "            extent if match_raster == None. Coordinates must be of the form [minX, minY, maxX, maxY].\n",
    "        :returns: (xr.DataArray) the clipped raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def reproject(in_raster: Union[xr.DataArray, str], match_raster: Union[xr.DataArray, str] = None,\n",
    "             out_path: str = None, custom_crs: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param match_raster: (xr.DataArray or str raster path) if defined, in_raster is\n",
    "            reprojected to match the Coordinate Reference System (CRS) of match_raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param custom_crs: (str) custom CRS string, only used if match_raster == None.\n",
    "        :returns: (xr.DataArray) the reprojected raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        # figure out what types of CRS strings exist / can be read by whatever library we use.\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def resample(in_raster: Union[xr.DataArray, str], match_raster: Union[xr.DataArray, str] = None,\n",
    "             out_path: str = None, custom_cell_size: Union[float, int] = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param match_raster: (xr.DataArray or str raster path) if defined, in_raster is\n",
    "            resampled to match the cell size of match_raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param custom_cell_size: (float or int) custom cell size, only used if match_raster == None.\n",
    "        :returns: (xr.DataArray) the resampled raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def mask(in_raster: Union[xr.DataArray, str], mask_shp: Union[gpd.GeoDataFrame, str] = None,\n",
    "            out_path: str = None, mask_cell_value: int = None, inverse: bool = False) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Primarily for masking rasters (i.e., FAC) by basin shapefiles, converting out-of-mask raster\n",
    "        values to NoData. A cell value can also be used to create a mask for integer rasters. \n",
    "        Note: default behavior (inverse=False) will make it so cells NOT COVERED by mask_shp -> NoData.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param mask_shp: (geopandas.GeoDataFrame or a str shapefile path) shapefile used for masking.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param mask_cell_value: (int, optional) if mask_shp == None this parameter can be used to mask\n",
    "            cells (i.e., change to NoData) if they equal mask_cell_value.\n",
    "        :param inverse: (bool, default=False) if True, cells that ARE COVERED by mask_shp -> NoData.\n",
    "        :returns: (xr.DataArray) the masked raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod  # FINISH THIS ONE\n",
    "    def binarize_categorical_rasters(cat_raster: Union[xr.DataArray, str], ignore_caregories: list = None,\n",
    "                                     out_path: str = None, split_rasters: bool = False) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        :param cat_raster: (xr.DataArray or str raster path) a categorical (dtype=int) raster with N\n",
    "            unique categories (i.e., land cover classes).\n",
    "        :param ignore_categories: (list of integers, default=None) category cell values not include\n",
    "            in the output raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param split_rasters: (bool, default=False) if True AND out_path != None, the directory\n",
    "            in out_path is used to store N separate .tif files for each unique cat_raster value.\n",
    "            Note that this is the behavior in V1.1 of FCPGTools.\n",
    "        :returns: (xr.DataArray) a N-band multi-dimensional raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # create/analyse flow accumulation rasters\n",
    "    @abc.abstractmethod\n",
    "    def fac_from_fdr(d8_fdr: Union[xr.DataArray, str], pour_points: dict = None,\n",
    "                    out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        :param d8_fdr: (xr.DataArray or str raster path) a D8 Flow Direction Raster (dtype=Int).\n",
    "        :param pour_points: (dict, default=None) a dictionary with coordinate tuples as keys\n",
    "            storing cell values. This allows the FAC to be made with boundary conditions such as\n",
    "            upstream basin pour points.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray) the Flow Accumulation Cells (FAC) raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod # FINISH THIS ONE\n",
    "    def parameter_accumulation(param_raster: Union[xr.DataArray, str],\n",
    "                               fac_raster: Union[xr.DataArray, str]) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        :param param_raster: (xr.DataArray or str raster path)\n",
    "        :param fac_raster: (xr.DataArray or str raster path) \n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray)...  as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod # FINISH THIS ONE\n",
    "    def find_pour_points() -> dict:\n",
    "        \"\"\"\n",
    "        :returns: (dict)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # make FCPG raster\n",
    "    @abc.abstractmethod # FINISH THIS ONE\n",
    "    def create_fcpg(param_accum_raster: Union[xr.DataArray, str],\n",
    "                    fac_raster: Union[xr.DataArray, str], out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray)...  as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # misc raster/utility functions\n",
    "    @abc.abstractmethod\n",
    "    def sample_raster(raster: xr.DataArray, coords: tuple) -> Union[float, int]:\n",
    "        \"\"\"\n",
    "        :param raster: (xr.DataArray) a raster as a DataArray in memory.\n",
    "        :param coords: (tuple) coordinate as (lat:float, lon:float) of the cell to be sampled.\n",
    "        :returns: (float or int) the cell value at param:coords.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_min_cell(raster: xr.DataArray) -> list[tuple, Union[float, int]]:\n",
    "        \"\"\"\n",
    "        Get the minimum cell coordinates + value from a raster.\n",
    "        :param raster: (xr.DataArray) a raster as a DataArray in memory.\n",
    "        :returns: (list) a list (len=2) with the min cell's coordinate tuple [0] and value [1]\n",
    "            i.e., [coords:tuple, value:Union[float, int]].\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_max_cell(raster: xr.DataArray) -> list[tuple, Union[float, int]]:\n",
    "        \"\"\"\n",
    "        Get the maximum cell coordinates + value from a raster.\n",
    "        :param raster: (xr.DataArray) a raster as a DataArray in memory.\n",
    "        :returns: (list) a list (len=2) with the max cell's coordinate tuple [0] and value [1]\n",
    "            i.e., [coords:tuple, value:Union[float, int]].\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update_cell_values(in_raster: Union[xr.DataArray, str], coords: tuple, value: Union[float, int],\n",
    "                          out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Update a specific raster cell's value based on it's coordindates. This is primarily used\n",
    "        to add upstream accumulation values as boundary conditions before making a FAC or FCPG.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param coords: (tuple) coordinate as (lat:float, lon:float) of the cell to be updated.\n",
    "        :param value: (float or int) new value to give the cell.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: param:in_raster with the updated cell value as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_shp_bbox(shp: Union[str, gpd.GeoDataFrame]) -> list:\n",
    "        \"\"\"\n",
    "        Get bbox coordinates of a shapefile.\n",
    "        :param shp: (geopandas.GeoDataFrame or str shapefile path) a georeferenced shapefile.\n",
    "        :returns: (list) list with bounding bbox coordinates - [minX, minY, maxX, maxY]\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_raster_bbox(raster: xr.DataArray): xr.DataArray, -> list:\n",
    "        \"\"\"\n",
    "        Get bounding box coordinates of a raster.\n",
    "        :param raster: (xr.DataArray or str raster path) a georeferenced raster.\n",
    "        :returns: (list) list with bounding bbox coordinates - [minX, minY, maxX, maxY]\n",
    "        \"\"\"\n",
    "        # this function is used to in verify_extent() as well as clip().\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def verify_extent(raster: xr.DataArray, coords: tuple) -> bool:\n",
    "        \"\"\"\n",
    "        Returns True if coordinates are contained within a given raster.\n",
    "        :param raster: (xr.DataArray or str raster path) a georeferenced raster.\n",
    "        :param coords: (tuple) the input (lat:float, lon:float) to verify.\n",
    "        :returns: boolean. True if param:coords is w/in the spatial extent of param:raster. \n",
    "        \"\"\"\n",
    "        # Note: this function should be used within other functions that query \n",
    "            # a raster using lat/long coordinates.\n",
    "        # 1. get raster bbox coorindates\n",
    "        # 2. see if coords is within the bbox, return a boolean\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b619e6-0624-4ad7-b489-da69bb3ad178",
   "metadata": {},
   "source": [
    "## IOEngine - ABC\n",
    "\n",
    "**Description:** A Abstract Base Class that defines key reading, writing, and metadata updating functions that underpin most functions in `GeoSpatialEngine{Lite/Full}`.\n",
    "* `read_raster()`: reads a raster file into a `xarray.DataArray`.\n",
    "* `write_raster()`: saves a `xarray.DataArray` as a GeoTIFF (or other format) using `rioxarray`.\n",
    "* `update_metadata()`: updates the metadata of a raster file via `rioxarray` and/or `rasterio`.\n",
    "* `read_shapefile()`: read a shapefile into a `geopandas.GeoDataFrame`.\n",
    "* `write_shapefile()`: save a `geopandas.GeoDataFrame` to a shapefile.\n",
    "\n",
    "**Note:** Figure out how raster metadata is stored in .tif/.shp files as well as `xarray` + `geopandas`. **In general circle back to the metadata aspect of `IOEngine`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b4305aa0-b30d-42ac-ae92-c6915a646e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IOEngine(abc.ABC):\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def read_raster(raster_path: str) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Reads a raster file (and it's metadata) into a xarray.DataArray using rioxarray.\n",
    "        :param raster_path: (str) path to a raster file (.tif...other formats?)\n",
    "        :returns: (xarray.DataArray) the raster as a DataArray object in memory.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def write_raster(in_raster: xr.DataArray) -> str:\n",
    "        \"\"\"\n",
    "        Save an xarray.DataArray as a raster file using rioxarray.\n",
    "        :param in_raster: (xarray.DataArray) a in-memory DataArray raster.\n",
    "        :returns: the path where the raster was saved.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def update_metadata(in_raster: xr.DataArray, metadata_dict: dict) -> bool:\n",
    "        \"\"\"\n",
    "        Update a rasters metadata (handy when overwriting rasters with changes).\n",
    "        Note: COME BACK TO THIS -> not sure exactly how metadata is stored/\n",
    "        :param in_raster: COME BACK TO THIS -> add path support? or just xarray?\n",
    "        :param metadata_dict: COME BACK TO THIS\n",
    "        :returns: (boolean) True if the metadata update was completed, False if not.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def read_shapefile(shp_path: str) -> gpd.GeoDataFrame:\n",
    "        \"\"\"\n",
    "        Reads a .shp shapefile into a geopandas.GeoDataFrame.\n",
    "        :param shp_path: (str) path to a shapefile.\n",
    "        :returns: (gpd.GeoDataFrame) the shapefile in geopandas. \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def write_shapefile(in_shp: gpd.GeoDataFrame) -> str:\n",
    "        \"\"\"\n",
    "        Save a GeoDataFrame to a .shp file.\n",
    "        :param in_shp: (geopandas.GeoDataFrame) in-memory shapefile (with associated metadata).\n",
    "        :returns: (str) path where the shapefile was saved.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bbece-1811-4636-b31d-d9e59983ce96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GeoSpatialEngineFull - ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48a30d1-b1fe-4a25-a63a-c2b3f4ceacbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c19f278b-68f4-4331-b9ce-7339e2b44df9",
   "metadata": {},
   "source": [
    "## Software architecture schematic (from meeting w/ Paul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a2a3c6d-1bca-443e-95c6-620ef2729542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concrete implementation of GeoSpatialEngineLite.clip()\n",
      "Concrete implementation of GeoSpatialEngineLite.reproject()\n",
      "Concrete implementation of GeoSpatialEngineLite.resample()\n"
     ]
    }
   ],
   "source": [
    "########## base_classes.py #############\n",
    "# where ABCs are defines\n",
    "class GeoSpatialEngineLite_EXAMPLE(abc.ABC):\n",
    "    # ABC defining core functions\n",
    "    pass\n",
    "\n",
    "class GeoSpatialEngineFull_EXAMPLE(GeoSpatialEngineLite_EXAMPLE):\n",
    "    # ABC adding additional functions GeoSpatialEngineLite\n",
    "    pass\n",
    "\n",
    "class IOEngine_EXAMPLE(abc.ABC):\n",
    "    # ABC adding additional functions GeoSpatialEngineLite\n",
    "    pass\n",
    "\n",
    "########## engine.py #############\n",
    "# contains \"tech stack\" specific concrete implementations of the ABCs\n",
    "class PyShedSpatialEngineLite(GeoSpatialEngineLite_EXAMPLE):\n",
    "    # inherets from Lite\n",
    "    def clip(self):\n",
    "        print('Concrete implementation of GeoSpatialEngineLite.clip()')\n",
    "        pass\n",
    "    def reproject(self):\n",
    "        print('Concrete implementation of GeoSpatialEngineLite.reproject()')\n",
    "        pass\n",
    "    def resample(self):\n",
    "        print('Concrete implementation of GeoSpatialEngineLite.resample()')\n",
    "        pass\n",
    "\n",
    "class TauGDALSpatialEngineFull(GeoSpatialEngineFull_EXAMPLE):\n",
    "    # inherets from Full\n",
    "    def clip(self):\n",
    "        pass\n",
    "    def reproject(self):\n",
    "        pass\n",
    "    def resample(self):\n",
    "        pass\n",
    "\n",
    "class WhiteBoxSpatialEngineFull(GeoSpatialEngineFull_EXAMPLE):\n",
    "    def clip(self):\n",
    "        pass\n",
    "    def reproject(self):\n",
    "        pass\n",
    "    def resample(self):\n",
    "        pass\n",
    "        \n",
    "########## main.py ############# \n",
    "# where we run things\n",
    "pysheds_engine_lite = PyShedSpatialEngineLite()\n",
    "whitebox_engine = WhiteBoxSpatialEngineFull()\n",
    "\n",
    "########## tools.py ############# \n",
    "# where tools are provided (allowing for engine options)\n",
    "\n",
    "def resample_param(engine=pysheds_engine_lite) -> xr.DataArray:\n",
    "    engine.clip()\n",
    "    engine.reproject()\n",
    "    engine.resample()\n",
    "    pass\n",
    "\n",
    "# test - should print out 3 statements if engine=pysheds_engine_lite\n",
    "resample_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89894ffe-92ee-420a-9427-5b38803ee422",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Earlier stuff - Ignore for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6047dbd-5caf-4871-95ce-2854c0eb444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc  # for abstract base class design\n",
    "import os  # for file manipulations\n",
    "import xarray as xr  # for in memory raster manipulation\n",
    "import rioxarray  # for on disk manipulations (read/write)\n",
    "from typing import Union  # for better type-hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f3d336-5c6a-40b6-a777-479e0e6313e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186b4659-3007-4bc0-8b89-bfaa6f856ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a decorator to verify in and output paths\n",
    "def verify_path_dir(in_path: str, make_dir: bool = True) -> Union[bool, None]:\n",
    "    \"\"\"\n",
    "    Verifies that both an input path directories exist (for iterative use).\n",
    "    If not but the next higher level directory does exist (and make_dir=True), the directory is created.\n",
    "    :param in_path: str - a file path name.\n",
    "    :param make_dir: bool (defaults to True) - whether to make the directory is easily possible.\n",
    "    :returns: boolean - True is all input file directories exist or were created, false otherwise.\n",
    "    \"\"\"\n",
    "    status = False\n",
    "\n",
    "    # find if dir_path exists, or can be made\n",
    "    if isinstance(in_path, str):\n",
    "        dir_path = os.path.dirname(in_path)\n",
    "        if not os.path.exists(dir_path):\n",
    "            if make_dir:\n",
    "                if os.path.exists(os.path.dirname(dir_path)):\n",
    "                    try:\n",
    "                        print(f'Creating output directory: {dir_path}')\n",
    "                        os.makedirs(dir_path)\n",
    "                        status = True\n",
    "                    except Exception as e:\n",
    "                        print(f'Could not make {dir_path} due to the following exception {e}')\n",
    "                        return None\n",
    "        else:\n",
    "            status = True\n",
    "    else:\n",
    "        print(f'ERROR in :py:func:verify_path_dir() - in_path parameter is not a {type(in_path)} string!')\n",
    "        return None\n",
    "\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b534a55d-547a-456c-9744-043477b358ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# place to test out functions\n",
    "test_path = r'C:\\Users\\xrnogueira\\Documents\\FCPGtools\\try_this\\PR_test.ipynb'\n",
    "#  verify_path_dir(test_path, make_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc1739-e083-411b-8545-f4e308882745",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## `ReadWriteEngine` - Input/Output Engine Class\n",
    "**Notes:**\n",
    "* The idea here is that all writing and reading to `xarray` can be done using class methods.\n",
    "* Come back and add ways to write raster attributes using [`rioxarray.to_raster()`](https://corteva.github.io/rioxarray/stable/rioxarray.html#rioxarray.raster_array.RasterArray.to_raster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da4a845-4182-438b-a034-000d38eef8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadWriteEngine(abc.ABC):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def open_raster(self, in_raster_path: str) -> Union[xr.DataArray, None]:\n",
    "        \"\"\"\n",
    "        Reads a raster file from path into an xarray DataArray.\n",
    "        :param in_raster_path: (str) a valid path to a georeferenced raster.\n",
    "        :return: ([xr.DataArray, None]) a DataArray object if a valid path is given,\n",
    "        or None if in_raster_path does not exist.\n",
    "        \"\"\"\n",
    "        if os.path.exists(in_raster_path):\n",
    "            # use the rioxarray (via :param:engine) to open a .tif as a xr.DataArray\n",
    "            # this is an experimental technique? other option...xr.open_dataarray(in_raster_path, decode_coords='ALL', engine=\"rasterio\")\n",
    "            raster = rioxarray.open_rasterio(in_raster_path, parse_coordinates=True)\n",
    "            return raster\n",
    "\n",
    "        else:\n",
    "            print(f'ERROR: {in_raster_path} does not exist.')\n",
    "            return None\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_raster_info(self, in_raster: Union[str, xr.DataArray]) -> dict:\n",
    "        \"\"\"\n",
    "        Get raster information (used to inform geoprocessing parameters to match parameter grids to FDR)\n",
    "        :param in_raster: either a raster path string or a DataArray\n",
    "        :returns: a dictionary with key raster attributes\n",
    "        \"\"\"\n",
    "        return dict\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def write_raster(self, in_raster: xr.DataArray, out_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Reads a raster file from path into an xarray DataArray.\n",
    "        :param in_raster: (xr.DataArray) a valid path to a georeferenced raster.\n",
    "        :param out_path: (str) a .tif path to write the raster to.\n",
    "        :return: (str) out_path that the raster was writted to (if successful).\n",
    "        \"\"\"\n",
    "        # check if the output directory exists\n",
    "        out_dir = os.dirname(out_path)\n",
    "        if os.path.exists(out_dir):\n",
    "            pass\n",
    "\n",
    "        # if the output directory does not exist, make it (if we can find the higher level directory)\n",
    "        elif os.path.exists(os.dirname(out_dir)):\n",
    "            os.makedirs(out_dir)\n",
    "            pass\n",
    "\n",
    "        # if we can't find a place to make the output directory, return an error\n",
    "        else:\n",
    "            return print(f'ERROR: Directory {os.dirname(out_dir)} does not exist and/or cannot be made.')\n",
    "\n",
    "        # export the DataArry to a GeoTIFF raster (add tags or kwags later?)\n",
    "        try:\n",
    "            in_raster.to_raster(out_path, driver='GTiff', compute=True)\n",
    "            return out_path\n",
    "        except Exception as e:\n",
    "            return print(f'Could not save raster to {out_path}\\n Exception: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f95986-e577-4c7d-804b-67578e2bc939",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `GeospatialEngineFull` Class - uses `xarray`\n",
    "**Notes:**\n",
    "* I am starting with defining the complete geospatial engine, then we can consider which aspects can be pulled in to `GeoSpatialEngineLite`.\n",
    "    * There will be duplicate techniques to do the same thing between pysheds vs taudem as well as GDAL vs xarray.\n",
    "* **Choose between an `xarray.DataArray` vs `xarray.Dataset` implementation!**\n",
    "* The idea here is that `xarray` data comes in, and `xarray` data comes out! **All writing and reading is stored in the `IOEngine` class.*\n",
    "\n",
    "**Class methods:**\n",
    "* Get a parameter grid aligned (splits `resampleParam()` into 3 functions):\n",
    "    * `reproject_raster()` - uses [`rioxarray.reproject_match()`](https://corteva.github.io/rioxarray/stable/rioxarray.html?highlight=write_crs#rioxarray.raster_array.RasterArray.reproject_match) OR [`rioxarray.reproject()`](https://corteva.github.io/rioxarray/stable/rioxarray.html#rioxarray.raster_dataset.RasterDataset.reproject) to reproject a raster.\n",
    "    * `resample_raster()` - uses \n",
    "    * `clip_raster()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f716319a-30ce-4a4f-86fd-593fc31138c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSpatialEngineLite(abc.ABC):\n",
    "\n",
    "    # NOTE: On second thought would this work better as a function?\n",
    "    class GDALWarp():\n",
    "        \"\"\"\n",
    "        GDALWarp wrapper to align a raster (via reprojection and/or resampling and/or clipping) with another raster.\n",
    "        Alternatively, the GDALWarp command can be customized beyond defeault behavior pythonically.\n",
    "        Use GDALWarp.execute() to execute on the command line via subprocesses.\n",
    "        If the existing pamarmeters don't achieve the use case, one can pass in a custom gdal command via .execute(custom_cmd:str)\n",
    "        \"\"\"\n",
    "\n",
    "        def add_resample(self, add: bool, xsize: Union[int, float], ysize: Union[int, float] = None) -> str:\n",
    "            if add:\n",
    "                if ysize is None:\n",
    "                    ysize = xsize\n",
    "                return f' -tr {xsize} {ysize}'\n",
    "            else:\n",
    "                return ''\n",
    "\n",
    "        def add_reproject(self, add: bool, fdrcrs: str) -> str:\n",
    "            if add:\n",
    "                return f' -t_srs {fdrcrs}'\n",
    "            else:\n",
    "                return ''\n",
    "\n",
    "        def add_clip(self, add: bool, xminmax: tuple, yminmax: tuple) -> str:\n",
    "            if add:\n",
    "                return f' -te {xminmax[0]} {yminmax[0]} {xminmax[1]} {yminmax[1]}'\n",
    "            else:\n",
    "                return ''\n",
    "\n",
    "        def execute(self, in_raster: str, out_raster: str, match_raster: str, optimize_cores: bool = True,\n",
    "                    reproject: bool = True, resample: bool = True, clip: bool = True,\n",
    "                    custom_cmd: str = None, new_dtype: str = None, new_cellsize: Union[float, int] = None,\n",
    "                    new_nodata: int = None, override_crs: str = None) -> str:\n",
    "            \"\"\"\n",
    "            Executes GDALWarp cmd\n",
    "            \"\"\"\n",
    "\n",
    "            # get params from raster info or override\n",
    "            # mock params...\n",
    "            cores, resample_method,  nodata, dtype, in_raster, out_raster = [1, 'bilinear', -1, 'int8', 'test_in.tif', 'test_out.tif']\n",
    "\n",
    "            # build end ofthe command\n",
    "            end_str = ' -co \"PROFILE=GeoTIFF\" -co \"TILED=YES\" -co \"SPARSE_OK=TRUE\" -co \"COMPRESS=LZW\" -co' \\\n",
    "                f' \"ZLEVEL=9\" -co \"NUM_THREADS={cores}\" -co \"BIGTIFF=IF_SAFER\" -r {resample_method} -dstnodata ' \\\n",
    "                f'{nodata} -ot {dtype} {in_raster} {out_raster}'\n",
    "\n",
    "            # add each warp command\n",
    "            resample_str = self.add_resample(bool(resample), 999, 999)\n",
    "            project_str = self.add_reproject(bool(reproject), fdrcrs='TESTCRS')\n",
    "            clip_str = self.add_clip(bool(clip), xminmax=(0, 9), yminmax=(0, 9))\n",
    "\n",
    "            # build final parameter -  then execute!\n",
    "            gdal_cmd = 'gdalwarp -overwrite' + resample_str + project_str + clip_str + end_str\n",
    "\n",
    "            return gdal_cmd\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def recode_d8_fdr(self) -> str:\n",
    "        \"\"\"\n",
    "        Recode a 8 directional Flow Direction Raster (FDR). Default is ESRI-TauDEM.\n",
    "        :param in_raster:\n",
    "        :param recode_dict: (optional, dict) an 8 item dictionary like {2: 4, 3: 6, ...}\n",
    "        that allows for custom raster recoding.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27836c36-5faf-4e4d-b878-03fa8f32eedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gdalwarp -overwrite -tr 999 999 -t_srs TESTCRS -te 0 0 9 9 -co \"PROFILE=GeoTIFF\" -co \"TILED=YES\" -co \"SPARSE_OK=TRUE\" -co \"COMPRESS=LZW\" -co \"ZLEVEL=9\" -co \"NUM_THREADS=1\" -co \"BIGTIFF=IF_SAFER\" -r bilinear -dstnodata -1 -ot int8 test_in.tif test_out.tif'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_test = r'test_in.tif'\n",
    "out_test = r'test_out.tif'\n",
    "match_test = r'test_match.tif'\n",
    "\n",
    "engine = GeoSpatialEngineLite.GDALWarp()\n",
    "\n",
    "engine.execute(in_test, out_test, match_test)\n",
    "\n",
    "# see if we need to get \"\" around some cmd keywords?\n",
    "\n",
    "# Notes:\n",
    "# resample, reproject, clip could be functions in the GeoSpatialEngine\n",
    "def clip(engine='gdal'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca8021-1bb8-4805-8d62-a9d054c4b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSpatialEngineFull(abc.ABC):\n",
    "\n",
    "    # define basic raster functions to prep parameter grids W/O GDAL\n",
    "    @abc.abstractmethod\n",
    "    def reproject_raster(self, in_raster: Union[str, xr.DataArray],\n",
    "                         out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Reproject a raster using GDAL warp\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def resample_raster(self, in_raster: Union[str, xr.DataArray],\n",
    "                        out_path: str = None) -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    v1 - use GDAL warp\n",
    "    :returns: xarray DataArray resampled\n",
    "    \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def clip_raster(self, in_raster: Union[str, xr.DataArray],\n",
    "                    out_path: str = None) -> xr.DataArray:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e317b-0c54-4178-addd-9cbeddebd1ac",
   "metadata": {},
   "source": [
    "## Tools/stand-alone functions\n",
    "* `requires_full_engine()` - a decorator function that verifies if a given function is available in the engine being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd455e-1cfd-4848-baab-2288f184b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def requires_full_engine(func: callable, *args, **kwargs) -> callable:\n",
    "    \"\"\"\n",
    "    A decorator to check if the full engine is required\n",
    "    \"\"\"\n",
    "    def full_engine_function(engine, *args, **kwargs) -> any:\n",
    "        if not isinstance(engine, FullEngine):\n",
    "            raise ValueError(f'Invalid engine type. Function {func.__name__} requires FullEngine')\n",
    "        return func(engine, *args, **kwargs)\n",
    "    return full_engine_function\n",
    "\n",
    "\n",
    "def get_cores() -> int:\n",
    "    \"\"\"\n",
    "    Finds the # of cores available for multiprocessing\n",
    "    \"\"\"\n",
    "    return int"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
