{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3afad325-74f5-4377-9a51-414b4cb0177f",
   "metadata": {},
   "source": [
    "FCPG Tools Refactoring - Abstract Base Classes (ABC) v1\n",
    "========================================================\n",
    "**By:** @xaviernogueira\n",
    "\n",
    "**Design philosphy:**\n",
    "* Single responsibility - all functions should do a single task. Their functionality should not be repeated in other functions.\n",
    "* Object oriented - Python class objects will be used to produce cleaner looking code as well as enable storage of relevant parameters between steps. Rasters will be stored in memory rather than being constantly written to disk.\n",
    "* Modular - while the existing installation of FCPGTools pulls all tools in as functions, in version 2.0.0 there will be multiple modules/classes containing functions. This allows for lighter weight imports avoiding GDAL and TauDEM dependencies. This also allows for expirementation with new geoprocessing engines (i.e., [`pysheds`](https://github.com/mdbartos/pysheds)).\n",
    "* Modern Python formatting - all functionality will be written following the [PEP8](https://peps.python.org/pep-0008/) style guide to match modern programming conventions.\n",
    "\n",
    "**New features:**\n",
    "* Multi-band support - since most hydrology relevant parameter grids are multi-band (with bands representing the time axis), all functions should work effectively the same regardless of how many bands are present. This can be handled by switching to an [`xarray`](https://docs.xarray.dev/en/stable/) tech stack.\n",
    "* Pipeline facilitation - there should be oppurtunities to automate large parts of the work flow with no intervention. This will require certain function parameters to be pulled from raster metadata. Additionally, this requires replacing the existing design where rasters are read/write by [rasterio](https://rasterio.readthedocs.io/en/latest/) to a design **where raster objects can be held in memory between steps.**\n",
    "* Performance optimization as a default - while some functions give the user an oppurtunity to input the # of cores they want to use on their computer, this optional parameter will likely not get used by more novice end users. Therefore I propose a workflow where a simple boolean `param:optimize` can control whether multi-processing is used. If `optimize=True` the program should automatically be able to identify the # of cores to use and allocate computation resources accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1496bb8a-258b-4878-9f02-0ae1a2edae8f",
   "metadata": {},
   "source": [
    "# GeoSpatial/IO Engine Abstract Base Classes\n",
    "\n",
    "**Description:** The idea here is that there is a set of funcitons that are deemed core/lite. **These functions are made concrete in different tech-stacks**, inhereting from the Abstract Base Class (think ODM2 API implementation). The `GeoSpatialEngineFull` ABC inehretes from the lite ABC, and is made concrete (i.e., inhereted from) using additional engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f56f29-d274-4d24-951d-d5ff7859cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "from typing import Union\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dfa64-2ab6-48ad-9aae-f3ee2a84e33b",
   "metadata": {},
   "source": [
    "## GeoSpatialEngineLite - ABC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3fa3bf-1e7d-4a4d-b280-9f00ec2b59a7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Key functions\n",
    "* **Prepare DEM Raster:**\n",
    "    * `fix_pits()`: **out-of-scope function we could add**\n",
    "    * `fix_depressions()`: **out-of-scope function we could add**\n",
    "    * `fix_flats()`: **out-of-scope function we could add**\n",
    "    * Note: These functions was not originally included in [`FCPGTools-1.1`](https://github.com/usgs/water-fcpg-tools), but are made easy by [PySheds](https://github.com/mdbartos/pysheds).\n",
    "* **Prepare Flow Direction Raster:**\n",
    "    * `d8_fdr()`: makes a D8 Flow Direction Raster (FDR) from a DEM raster.\n",
    "    * `convert_d8()`: converts D8 FDR encodings (i.e., ESRI -> TauDEM).\n",
    "    \n",
    "* **Masking functions:**\n",
    "    * `spatial_mask()`: masks a raster using a shapefile or a binary raster.\n",
    "    * `value_mask():` masks a raster using a value threshold.\n",
    "        * **Note:** This function is a more generalizable version of the `makeStreams()` functionality in the V1 toolset. This is because the repvious function was simply a value mask expecting FAC values, which could be useful to find accumulation pathways broadly (i.e., small scale drainages) that would not be described as streams.\n",
    "    * `nodata_mask()`: essentially uses `value_mask()` but first either reads the nodata value from raster metadata, or applies a user defined value.\n",
    "    * `apply_mask()`: applies a binary mask (can be made from any of the above three functions) to convert out-of-mask cells to nodata.\n",
    "    \n",
    "\n",
    "* **Prepare parameter grids:**\n",
    "    * `clip()`: rectangularly clip a raster to match the spatial extent of another raster (or custom bounding box coordinates or shapefile). \n",
    "    * `resample()`: resample a raster to match the cell size of another raster (or a custom cell size). \n",
    "    * `reproject()`: reproject a raster to match another raster (or a custom CRS).\n",
    "    * `binarize_categorical_rasters()`: one-hot-encode a categorical parameter raster so that each unique category is represented w/ cell=1 in it's band in a multi-dimensional DataArray.\n",
    "    \n",
    "* **Flow Accumulation Raster (FAC) related functions:**\n",
    "    * `accumulate_flow()`: create a FAC from a FDR.\n",
    "    * `parameter_accumulation`: create a parameter grid accumulation raster (can be multi-dimensional along a time axis). \n",
    "    * `nodata_accumulation()`: combines `nodata_mask()` and `parameter_accumulation()` to create an accumulation raster of nodata cells.\n",
    "    * `find_basin_pour_points()`: find basin pour points (outflow cells) and their accumulation values (cell or paramater).\n",
    "    * Note: We need to be able to create both FAC and parameter accumulation rasters **given boundary conditions (i.e., upstream basin pour points)** -> this is done by first using update_raster_values() before creating the FAC and in V2 could simply be a parameter of `parameter_accumulation()` and `accumulate_flow()`.\n",
    "* **Flow Conditioned Parameter Grid (FCPG):**\n",
    "    * `make_fcpg()`: create a multi-dimensional FCPG raster for a parameter grid stack.\n",
    "\n",
    "**Notes:** \n",
    "* **For all functions:** MULTI-DIMENSION IN -> MULTI-DIMENSION OUT.\n",
    "* Note that parameter signatures `param:fdr` equate to a D8 FDR, while `param:dinf_fdr` correpsonds to D-Infinity FDRs.\n",
    "* For `d8_fdr()` I am making `xarray.DataArray` returns default behavior, although one can save the intermediate files if they decide to.\n",
    "* If we go past TauDEM we should support (and have some automatic way to verify) D8 cell value meanings?\n",
    "* Reading and writing rasters files should *ideally* be done in a separate IOEngine ABC. An issue we may run into here is that some engines (i.e., GDAL) work directly with paths via cmd line, therefore one would not need a xarray -> read/write functionality necessarily. **(bring up in a meeting)**.\n",
    "* As of now, pour point boudnary conditions will be stored in a dictionary - `{(lat:float, lon:float): updated_cell_value:int}`.\n",
    "    * **Workflow:** First mask by downstream basin, and then add the upstream pour points accumulation values to the masked raster.\n",
    "* **Bring up:** Given the multi-dimensional capabilities this supports, we could handle NetCDF and Zarr inputs/outputs ([already in xarray](https://clouds.eos.ubc.ca/~phil/courses/parallel_python/02_xarray_zarr.html)). Also should have multifile input support via `xarray.open_mfDataset()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d868a01b-5a30-4781-8ec0-db5c67be6d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSpatialEngineLite(abc.ABC):\n",
    "    \"\"\"Abstract Base Class for the core FCPGTools functions that can be ran w/o TauDEM.\"\"\"\n",
    "\n",
    "    #  Prepare flow direction raster (FDR)\n",
    "    @abc.abstractmethod\n",
    "    def fix_pits(dem: Union[xr.DataArray, str], out_path: str = None, fix: bool = True) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Detect and fills single cell \"pits\" in a DEM raster using pysheds: .detect_pits()/.fill_pits().\n",
    "        :param dem: (xr.DataArray or str raster path) the input DEM raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param fix: (bool, default=True) if False, a print statement warns of the # of single cell pits\n",
    "            without fixing them. The input raster is returned as is.\n",
    "        :returns: (xr.DataArray) the filled DEM an xarray DataArray object (while fix=True).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fix_depressions(dem: Union[xr.DataArray, str], out_path: str = None, fix: bool = True) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Detect and fills multi-cell \"depressions\" in a DEM raster using pysheds: .detect_depressions()/.fill_depressions().\n",
    "        :param dem: (xr.DataArray or str raster path) the input DEM raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param fix: (bool, default=True) if False, a print statement warns of the # of dpressions\n",
    "            without fixing them. The input raster is returned as is.\n",
    "        :returns: (xr.DataArray) the filled DEM an xarray DataArray object (while fix=True).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def fix_flats(dem: Union[xr.DataArray, str], out_path: str = None, fix: bool = True) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Detect and resolves \"flats\" in a DEM using pysheds: .detect_flats()/.resolve_flats().\n",
    "        :param dem: (xr.DataArray or str raster path) the input DEM raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param fix: (bool, default=True) if False, a print statement warns of the # flats\n",
    "            without fixing them. The input raster is returned as is.\n",
    "        :returns: (xr.DataArray) the resolved DEM an xarray DataArray object (while fix=True).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def d8_fdr(dem: Union[xr.DataArray, str], out_path: str = None,\n",
    "               out_format: str = 'TauDEM') -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Creates a flow direction raster from a DEM. Can either save the raster or keep in memory.\n",
    "        :param dem: (xr.DataArray or str raster path) the DEM from which to make the FDR.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param out_format: (str, default=TauDEM) type of D8 flow direction encoding for output.\n",
    "        :returns: the FDR as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def convert_d8(d8_fdr: Union[xr.DataArray, str], out_path: str = None,\n",
    "                   in_format: str = 'ESRI', out_format: str = 'TauDEM') -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Recodes a D8 FDR between different formats (default is ESRI -> TauDEM, int8 dytpe). \n",
    "        Other optionis D-Infinity (float64 dtype).\n",
    "        :param d8_fdr: (xr.DataArray or str raster path) a D8 Flow Direction Raster (dtype=Int).\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param in_format: (str, default=TauDEM) input rasters D8 flow direction encoding type.\n",
    "        :param out_format: (str, default=TauDEM) type of D8 flow direction encoding for output.\n",
    "        :returns: the recoded D8 FDR as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def find_cell_downstream(d8_fdr: Union[xr.DataArray, str], coords: tuple) -> tuple:\n",
    "        \"\"\"\n",
    "        Uses a D8 FDR to find the cell center coordinates downstream from any cell (specified\n",
    "        Note: this replaces py:func:FindDownstreamCellTauDir(d, x, y, w) in the V1.1 repo.\n",
    "        :param d8_fdr: (xr.DataArray or str raster path) a D8 Flow Direction Raster (dtype=Int).\n",
    "        :param coords: (tuple) the input (lat:float, lon:float) to find the next cell downstream from.\n",
    "        :returns: (tuple) an output (lat:float, lon:float) representing the cell center coorindates\n",
    "            downstream from the cell defined via :param:coords.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # raster masking functions\n",
    "    @abc.abstractmethod\n",
    "    def spatial_mask(in_raster: Union[xr.DataArray, str], mask_shp: Union[gpd.GeoDataFrame, str] = None,\n",
    "            out_path: str = None, mask_cell_value: int = None, inverse: bool = False) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Primarily for masking rasters (i.e., FAC) by basin shapefiles, converting out-of-mask raster\n",
    "        values to NoData. A cell value can also be used to create a mask for integer rasters.\n",
    "        Note: default behavior (inverse=False) will make it so cells NOT COVERED by mask_shp -> NoData.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param mask_shp: (geopandas.GeoDataFrame or a str shapefile path) shapefile used for masking.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param mask_cell_value: (int, optional) if mask_shp == None this parameter can be used to mask\n",
    "            cells (i.e., change to NoData) if they equal mask_cell_value.\n",
    "        :param inverse: (bool, default=False) if True, cells that ARE COVERED by mask_shp -> NoData.\n",
    "        :returns: (xr.DataArray) the output binary mask raster.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def value_mask(in_raster: Union[xr.DataArray, str], thresh: Union[int, float] = None, greater_than: bool = True,\n",
    "                   equals: int = None, out_mask_value: int = None, out_path: str = None, inverse: bool = False) -> xr.DataArray:\n",
    "        \"\"\"\"\n",
    "        Mask a raster via a value threshold. Primary use case is to identify high acumulation zones / stream cells.\n",
    "        Cells included in the mask are given a value of 1, all other cells are given a value of 0 (unless out_mask_value!=None).\n",
    "        Note: this function generalizes V1:pyfunc:makeStreams() functionality.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param thresh: (int or float, default=None) \n",
    "        :param greater_than: (bool, default=True) if False, only values less than param:thresh are included in the mask.\n",
    "        :param equals: (int, default=None) if not None, only cells matching the value of param:equals are included in the mask.\n",
    "        :param out_mask_value: (int, default=None) allows non-included cells to be given a non-zero integer value.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param inverse: (bool, default=False) if True, the inverse of the mask is made.\n",
    "        :returns: (xr.DataArray) the output binary mask raster.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def nodata_mask(in_raster: Union[xr.DataArray, str], inverse: bool = False,\n",
    "                    nodata_value: Union[float, int] = None, out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Creates an output binary raster based on an input where nodata values -> 1, and valued cells -> 0.\n",
    "        Note: while param:inverse=True this can be used with pyfunc:apply_mask() to match nodata cells between rasters.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param inverse: (bool, default=False) if True, values that are NOT nodata -> 1, and nodata values -> 0.\n",
    "        :param nodata_value: (float->np.nan or int) if the nodata value for param:in_raster is not in the metadata,\n",
    "            set this parameter to equal the cell value storing nodata (i.e., np.nan or -999).\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray) the output binary mask raster.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def apply_mask(in_raster: Union[xr.DataArray, str], mask_raster: Union[xr.DataArray, str],\n",
    "                   inverse: bool = False, out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Converts all values NOT included within a mask (i.e., value=0 while inverse=False) param:in_raster's nodata value.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param mask_raster: (xr.DataArray or str raster path) a binary \"mask\" raster where value=0 -> nodata in param:in_raster.\n",
    "        :param inverse: (bool, default=False) if True param:mask_raster cells with a value of 1 are converted to nodata.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray) the output raster with nodata cells.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # prepare parameter grid rasters\n",
    "    @abc.abstractmethod\n",
    "    def clip(in_raster: Union[xr.DataArray, str], match_raster: Union[xr.DataArray, str] = None,\n",
    "             out_path: str = None, custom_shp: Union[str, gpd.GeoDataFrame] = None,\n",
    "             custom_bbox: list = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Clips a raster to the rectangular extent (aka bounding box) of another raster (or shapefile).\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param match_raster: (xr.DataArray or str raster path) if defined, in_raster is\n",
    "            clipped to match the extent of match_raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param custom_shp: (str path or GeoDataFame, default=None) a shapefile that is used to define\n",
    "            the output extent if match_raster == None.\n",
    "        :param custom_bbox: (list, default=None) a list with bounding box coordinates that define the output\n",
    "            extent if match_raster == None. Coordinates must be of the form [minX, minY, maxX, maxY].\n",
    "        :returns: (xr.DataArray) the clipped raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def reproject(in_raster: Union[xr.DataArray, str], match_raster: Union[xr.DataArray, str] = None,\n",
    "             out_path: str = None, custom_crs: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Reprojects a raster to match another rasters Coordinate Reference System (CRS), or a custom CRS.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param match_raster: (xr.DataArray or str raster path) if defined, in_raster is\n",
    "            reprojected to match the Coordinate Reference System (CRS) of match_raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param custom_crs: (str) custom CRS string, only used if match_raster == None.\n",
    "        :returns: (xr.DataArray) the reprojected raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        # figure out what types of CRS strings exist / can be read by whatever library we use.\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def resample(in_raster: Union[xr.DataArray, str], match_raster: Union[xr.DataArray, str] = None,\n",
    "             out_path: str = None, custom_cell_size: Union[float, int] = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Resamples a raster to match another raster's cell size, or a custom cell size.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param match_raster: (xr.DataArray or str raster path) if defined, in_raster is\n",
    "            resampled to match the cell size of match_raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param custom_cell_size: (float or int) custom cell size, only used if match_raster == None.\n",
    "        :returns: (xr.DataArray) the resampled raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def binarize_categorical_rasters(cat_raster: Union[xr.DataArray, str], ignore_caregories: list = None,\n",
    "                                     out_path: str = None, split_rasters: bool = False) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        :param cat_raster: (xr.DataArray or str raster path) a categorical (dtype=int) raster with N\n",
    "            unique categories (i.e., land cover classes).\n",
    "        :param ignore_categories: (list of integers, default=None) category cell values not include\n",
    "            in the output raster.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param split_rasters: (bool, default=False) if True AND out_path != None, the directory\n",
    "            in out_path is used to store N separate .tif files for each unique cat_raster value.\n",
    "            Note that this is the behavior in V1.1 of FCPGTools.\n",
    "        :returns: (xr.DataArray) a N-band multi-dimensional raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        # use value_mask(equals=int) -> binary_mask_accumulation()\n",
    "        pass\n",
    "\n",
    "    # create/analyse flow accumulation rasters\n",
    "    @abc.abstractmethod\n",
    "    def accumulate_flow(d8_fdr: Union[xr.DataArray, str], upstream_pour_points: list = None,\n",
    "                    out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Create a Flow Accumulation Cell (FAC) raster from a TauDEM format D8 Flow Direction Raster.\n",
    "        :param d8_fdr: (xr.DataArray or str raster path) a TauDEM format D8 Flow Direction Raster (dtype=Int).\n",
    "        :param upstream_pour_points: (list, default=None) a list of lists each with with coordinate tuples\n",
    "            as the first item [0], and updated cell values as the second [1]. This allows the FAC to be made\n",
    "            with boundary conditions such as upstream basin pour points.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray) the Flow Accumulation Cells (FAC) raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def parameter_accumulation(param_raster: Union[xr.DataArray, str], fac_raster: Union[xr.DataArray, str],\n",
    "                              update_input: Union[dict, list] = None, update_add: bool = False,\n",
    "                              out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Create a accumulation raster from an arbitrary parameter raster.\n",
    "        :param param_raster: (xr.DataArray or str raster path)\n",
    "        :param fac_raster: (xr.DataArray or str raster path) the Flow Accumulation Cells (FAC) raster.\n",
    "        :param update_input: (dict or list, optional) allows boundary conditions to be set by updating the\n",
    "            input param:param_raster with upstream pour point accumulation sums. Either a list of lists or a dictionary.\n",
    "            with integer keys to reference band index storing list[coords:tuple, value:Union[float, int]].\n",
    "            Note: if the input is multi-dimensional this must be a dictionary.\n",
    "        :param add_update: (bool, default=False) if True while update_raster!=None, the update_raster dict\n",
    "             values are added to the parameter raster value instead of replacing them.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray) the parameter accumulation raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def find_basin_pour_points(fac_raster: Union[xr.DataArray, str],\n",
    "                         basins_shp: str = None, basin_id_field: str = None) -> dict:\n",
    "        \"\"\"\n",
    "        Find pour points (aka outflow cells) in a FAC raster by basin using a shapefile.\n",
    "        :param fac_raster: (xr.DataArray or str raster path) a Flow Accumulation Cell raster (FAC).\n",
    "        :param basins_shp: (str path) a .shp shapefile containing basin geometries.\n",
    "        :basin_id_field: default behavior is for each GeoDataFrame row to be a unique basin.s\n",
    "            However, if one wants to use a higher level basin id that is shared acrcoss rows,\n",
    "            this should be set to the column header storing the higher level basin id.\n",
    "        :returns: (dict) a dictionary with keys (i.e., basin IDs) storing coordinates as a tuple(lat, lon).\n",
    "        \"\"\"\n",
    "        # check extents of shapefile bbox and make sure all overlap the FAC raster extent\n",
    "        pass\n",
    "\n",
    "    # make FCPG raster\n",
    "    @abc.abstractmethod\n",
    "    def make_fcpg(param_accum_raster: Union[xr.DataArray, str], fac_raster: Union[xr.DataArray, str],\n",
    "                    ignore_nodata: bool = False, out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Creates a Flow Conditioned Parameter Grid raster by dividing a paramater accumulation\n",
    "        raster by a Flow Accumulation Cell (FAC) raster. FCPG = param_accum / fac.\n",
    "        :param param_accum_raster: (xr.DataArray or str raster path)\n",
    "        :param fac_raster: (xr.DataArray or str raster path) input FAC raster.\n",
    "        :param ignore_nodata: (bool, default=False) by default param_accum_raster cells with nodata\n",
    "            are kept as nodata. If True, the lack of parameter accumulation is ignores, and the FAC value\n",
    "            if given to the cell without adjustment.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray) the output FCPG raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff4b03f-e9d0-4389-bbee-2b9878e883cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Underlying utility functions\n",
    "\n",
    "* **Batch/pipeline functions:**\n",
    "    * `batch_process`: applies a function to each `xr.DataArray` within a `xr.Dataset`.\n",
    "\n",
    "* **Other raster/utility functions:**\n",
    "    * `query_point()`: gets a cell value from a raster by specifying coordinates. \n",
    "    * `get_min_cell()`: gets the coordinates and value of a raster's minimum cell value. \n",
    "    * `get_max_cell()`: gets the coordinates and value of a raster's maximum cell value. \n",
    "    * `update_raster_values()`: updates the value of a raster cell specified by coordinates.\n",
    "    * `get_shp_bbox()`: gets the spatial extent of a shapefile as a bounding box list.\n",
    "    * `get_raster_bbox()`: gets the spatial extent of a raster as a bounding box list.\n",
    "    * `verify_extent()`: check if coordinates are contained by a raster's extent.\n",
    "    * `change_nodata()`: change the nodata value of a raster.\n",
    "    * `minimize_extent()`: clip a raster to it's minimum rectangular extent containing all non-nodata values.\n",
    "    * `convert_dtype():` **COME BACK TO THIS**`\n",
    "    \n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* `param:in_raster` is used when the input raster is altered in some way, while `param:raster` is used when there is no edits made to the file (i.e., just getting info).\n",
    "* **TO-DO:** Figure out if xr.DataArray objects can be altered in place? This will effect whether we want inplace=True parameters in raster utlity functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c414e8fd-5406-43cf-90f9-9db67b77499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    @abc.abstractmethod\n",
    "    def batch_process(Dataset: xr.Dataset, function: callable = None,\n",
    "                      out_path: str = None, **kwargs: dict) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Applies a function to each DataArray in a Dataset (should this be built into the functions themselves??)\n",
    "        :param Dataset: (xr.Dataset) an xarray Dataset where all DataArrays are ready to be processed together.\n",
    "        :param function: (callable) a function to apply to the Dataset.\n",
    "        :param out_path: (str path, default=None) a zarr or netcdf extension path to save the Dataset.\n",
    "        :param **kwargs: (dict) allows for non-default keyword parameters for param:function to be specified.\n",
    "        :returns: (xr.Dataset) the output Dataset with each DataArray altered by param:function.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def query_point(raster: xr.DataArray, coords: tuple) -> Union[float, int]:\n",
    "        \"\"\"\n",
    "        :param raster: (xr.DataArray) a raster as a DataArray in memory.\n",
    "        :param coords: (tuple) coordinate as (lat:float, lon:float) of the cell to be sampled.\n",
    "        :returns: (float or int) the cell value at param:coords.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_min_cell(raster: xr.DataArray) -> list[tuple, Union[float, int]]:\n",
    "        \"\"\"\n",
    "        Get the minimum cell coordinates + value from a raster.\n",
    "        :param raster: (xr.DataArray) a raster as a DataArray in memory.\n",
    "        :returns: (list) a list (len=2) with the min cell's coordinate tuple [0] and value [1]\n",
    "            i.e., [coords:tuple, value:Union[float, int]].\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_max_cell(raster: xr.DataArray) -> list[tuple, Union[float, int]]:\n",
    "        \"\"\"\n",
    "        Get the maximum cell coordinates + value from a raster.\n",
    "        :param raster: (xr.DataArray) a raster as a DataArray in memory.\n",
    "        :returns: (list) a list (len=2) with the max cell's coordinate tuple [0] and value [1]\n",
    "            i.e., [coords:tuple, value:Union[float, int, np.array]].\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update_raster_values(in_raster: Union[xr.DataArray, str], coords: tuple, value: Union[float, int],\n",
    "                        out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Update a specific raster cell's value based on it's coordindates. This is primarily used\n",
    "        to add upstream accumulation values as boundary conditions before making a FAC or FCPG.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param coords: (tuple) coordinate as (lat:float, lon:float) of the cell to be updated.\n",
    "        :param value: (float or int) new value to give the cell.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :returns: param:in_raster with the updated cell value as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def change_nodata(in_raster: Union[xr.DataArray, str], nodata_value: Union[float, int],\n",
    "                      out_path: str = None, convert_dtype: bool = True) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Update a specific raster nodata value.\n",
    "        :param in_raster: (xr.DataArray or str raster path) input raster.\n",
    "        :param nodata_value: (float or int) new value to give nodata cells before saving.\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param convert_dtype: (bool, default=True) if param:nodata_value is non-compatible\n",
    "            with in_raster's dtype, a dtype conversion is default unless False.\n",
    "        :returns: param:in_raster with the updated nodata values as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        # Note for dev: we need to understand xarray's handling of nodata values\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def change_dtype(in_raster: Union[xr.DataArray, str], out_dtype: str,\n",
    "                     out_path: str = None, allow_rounding: bool = False) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Change a rasters datatype to another valid xarray datatype.\n",
    "        :param in_raster: (xr.DataArray or str path) input raster.\n",
    "        :param out_dtype: (str) a valid xarray datatype string (i.e., float64, int64...).\n",
    "        :param out_path: (str, default=None) defines a path to save the output raster.\n",
    "        :param allow_rounding: (bool, default=False) allows rounding of float -> int.\n",
    "        :returns: (xr.DataArray) the raster with it's dtype changed.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_raster_bbox(raster: xr.DataArray) -> list:\n",
    "        \"\"\"\n",
    "        Get bounding box coordinates of a raster.\n",
    "        :param raster: (xr.DataArray or str raster path) a georeferenced raster.\n",
    "        :returns: (list) list with bounding bbox coordinates - [minX, minY, maxX, maxY]\n",
    "        \"\"\"\n",
    "        # this function is used to in verify_extent() as well as clip().\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def verify_extent(raster: xr.DataArray, coords: tuple) -> bool:\n",
    "        \"\"\"\n",
    "        Returns True if coordinates are contained within a given raster.\n",
    "        :param raster: (xr.DataArray or str raster path) a georeferenced raster.\n",
    "        :param coords: (tuple) the input (lat:float, lon:float) to verify.\n",
    "        :returns: boolean. True if param:coords is w/in the spatial extent of param:raster.\n",
    "        \"\"\"\n",
    "        # Note: this function should be used within other functions that query\n",
    "        # a raster using lat/long coordinates.\n",
    "        # 1. get raster bbox coorindates\n",
    "        # 2. see if coords is within the bbox, return a boolean\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def minimize_extent(in_raster: Union[xr.DataArray, str],\n",
    "                        nodata_value: Union[float, int] = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Minimizes the extent of a raster to the bounding box of all non-nodata cells.\n",
    "        Useful after raster operations where extents don't match and nodata values are propageted forwards.\n",
    "        :param in_raster: (xr.DataArray or str raster path) the input raster.\n",
    "        :param nodata_value: (float->np.nan or int) if the nodata value for param:in_raster is not in the metadata,\n",
    "            set this parameter to equal the cell value storing nodata (i.e., np.nan or -999).\n",
    "        :returns: (xr.DataArray) the clipped output raster as a xarray DataArray object.\n",
    "        \"\"\"\n",
    "        # if no nodata values -> return in_raster\n",
    "        # else return the minimum extent\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_shp_bbox(shp: Union[str, gpd.GeoDataFrame]) -> list:\n",
    "        \"\"\"\n",
    "        Get bbox coordinates of a shapefile.\n",
    "        :param shp: (geopandas.GeoDataFrame or str shapefile path) a georeferenced shapefile.\n",
    "        :returns: (list) list with bounding bbox coordinates - [minX, minY, maxX, maxY]\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9498770-5fbb-463d-a221-380654ffdc46",
   "metadata": {},
   "source": [
    "## Pipeline functions?\n",
    "\n",
    "**Description:** Certain processes could be wrapped into pipelines. Also a pipeline should definetly exist to process each DataArray with `xarray.Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b619e6-0624-4ad7-b489-da69bb3ad178",
   "metadata": {
    "tags": []
   },
   "source": [
    "## IOEngine - ABC\n",
    "\n",
    "**Description:** A Abstract Base Class that defines key reading, writing, and metadata updating functions that underpin most functions in `GeoSpatialEngine{Lite/Full}`.\n",
    "* `read_raster()`: reads a raster file into a `xarray.DataArray`.\n",
    "* `read_multi_rasters()`: reads multiple rasters files or DataArrays into a `xarray.Dataset` for batch processing.\n",
    "* `write_raster()`: saves a `xarray.DataArray` as a GeoTIFF (or other format) using `rioxarray`.\n",
    "* `write_dataset()`: saves a `xarray.Dataset` as a NetCDF, Zarr, or multiple GeoTIFFs.\n",
    "* maybe: `update_metadata()`: updates the metadata of a raster file via `rioxarray` and/or `rasterio`.\n",
    "* `read_shapefile()`: read a shapefile into a `geopandas.GeoDataFrame`.\n",
    "* `write_shapefile()`: save a `geopandas.GeoDataFrame` to a shapefile.\n",
    "\n",
    "**Note:** Figure out how raster metadata is stored in .tif/.shp files as well as `xarray` + `geopandas`. **In general circle back to the metadata aspect of `IOEngine`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4305aa0-b30d-42ac-ae92-c6915a646e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IOEngine(abc.ABC):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def read_raster(raster_path: str) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Reads a raster file (and it's metadata) into a xarray.DataArray using rioxarray.\n",
    "        :param raster_path: (str path) path to a raster file that is either ['GeoTIFF', 'Zarr', 'NetCDF'].\n",
    "        :returns: (xarray.DataArray) the raster as a DataArray object in memory.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def read_multi_rasters(raster_dict: dict = None, raster_dir: str = None) -> xr.Dataset:\n",
    "        \"\"\"\n",
    "        Reads multiple rasters (either from path or xr.DataArrays) into a single xr.Dataset.\n",
    "        :param raster_dict: (dict, default=None) a dictionary with data names as keys, and either str paths\n",
    "            to raster files, or DataArrays, i.e., {'Precipitation': xr.DataArray}.\n",
    "        :param raster_dir: (str path, default=None) if raster_dict=None setting this to a valid\n",
    "            directory path containing multiple raster files will add them into a single Dataset with\n",
    "            names matching the file names (index arbitrary unless raster file names start with numbers).\n",
    "        :returns: (xr.Dataset) each raster file as a DataArray wrapped within a single xarray Dataset object.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def write_raster(in_raster: xr.DataArray, out_format: str) -> str:\n",
    "        \"\"\"\n",
    "        Save an xarray.DataArray as a raster file using rioxarray.\n",
    "        :param in_raster: (xarray.DataArray) a in-memory DataArray raster.\n",
    "        :param out_format: (str) one of the following - ['GeoTIFF', 'Zarr', 'NetCDF']\n",
    "        :returns: the path where the raster was saved.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def write_Dataset(in_Dataset: xr.Dataset, out_dir: str = None,\n",
    "                      out_format: str = None, out_names: dict = None) -> str:\n",
    "        \"\"\"\n",
    "        Saves a `xarray.Dataset` as a NetCDF, Zarr, or multiple GeoTIFFs.\n",
    "        :param in_Dataset: (xarray.DataArray) a in-memory DataArray raster.\n",
    "        :param out_path: (str path) either a file path to save a ND-raster (zarr or netcdf only),\n",
    "            or a directory to save multiple GeoTIFFs.\n",
    "        :param out_format: (str) one of the following - ['Zarr', 'NetCDF', 'GeoTIFF'].\n",
    "            Note that if out_format='GeoTIFF', multiple GeoTIFFs will be written within \n",
    "            the directory containing out_path (if it isn't already a directory).\n",
    "        :returns: (str) the path to the file/directory where the rasters were saved.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def update_metadata(in_raster: xr.DataArray, metadata_dict: dict) -> bool:\n",
    "        \"\"\"\n",
    "        Update a rasters metadata (handy when overwriting rasters with changes).\n",
    "        Note: COME BACK TO THIS -> not sure exactly how metadata is stored/\n",
    "        :param in_raster: COME BACK TO THIS -> add path support? or just xarray?\n",
    "        :param metadata_dict: COME BACK TO THIS\n",
    "        :returns: (boolean) True if the metadata update was completed, False if not.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def read_shapefile(shp_path: str) -> gpd.GeoDataFrame:\n",
    "        \"\"\"\n",
    "        Reads a .shp shapefile into a geopandas.GeoDataFrame.\n",
    "        :param shp_path: (str) path to a shapefile.\n",
    "        :returns: (gpd.GeoDataFrame) the shapefile in geopandas. \n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def write_shapefile(in_shp: gpd.GeoDataFrame) -> str:\n",
    "        \"\"\"\n",
    "        Save a GeoDataFrame to a .shp file.\n",
    "        :param in_shp: (geopandas.GeoDataFrame) in-memory shapefile (with associated metadata).\n",
    "        :returns: (str) path where the shapefile was saved.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bbece-1811-4636-b31d-d9e59983ce96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GeoSpatialEngineFull - ABC\n",
    "Contains functionality that cannot be recreated in `pysheds`, thereby requiring [`TauDEM`](https://hydrology.usu.edu/taudem/taudem5/) as likely dependency of an implementation of this ABC. \n",
    "\n",
    "**Functions to replicate (V1 version):**\n",
    "* `makeStreams()` -> can be in Lite engine in a more generalizble way -> `value_mask()`!\n",
    "* `distance_to_stream()`\n",
    "* `makeDecayGrid()`\n",
    "* `decayAccum()`\n",
    "* `ExtremeUpslopeValue()`\n",
    "\n",
    "Note that the work flow is as such: make streams -> find each cell's distance to the stream -> create a decay grid based on the inverse of that distance -> accumulate the decay grid (?). The extream upslope value seems to be a wrapper for some other TauDEM function, see if we can replicate.\n",
    "\n",
    "**GeoSpatialEngineFull Functions:**\n",
    "* `extreme_upslope_values()`: gets a max/min value from param:param_raster from the subset of all upslope cells for each cell in a FDR. In TauDEM this is the \"Extreme Upslope Value\" function.\n",
    "* `calculate_distance_to_stream()`: Create a raster where cell values represent the horizantal distance to the nearest stream ALONG the flow path.\n",
    "* `decay_accumulation()`: Create a decayed accumulation raster from a D-Infinity FDR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48a30d1-b1fe-4a25-a63a-c2b3f4ceacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSpatialEngineFull(GeoSpatialEngineLite):\n",
    "\n",
    "    # optimize cores for TauDEM functionality -> TauDEMEngine type thing\n",
    "    @abc.abstractmethod\n",
    "    def __init__():\n",
    "        self._cores = None\n",
    "\n",
    "    @abc.abstractproperty\n",
    "    def cores() -> int:\n",
    "        if self._cores is None:\n",
    "            self._cores = int(multiprocessing.cpu_count())\n",
    "        return self._cores\n",
    "\n",
    "    # TauDEM: Extreme upslope value\n",
    "    @abc.abstractmethod\n",
    "    def extreme_upslope_values(fdr: Union[xr.DataArray, str], param_raster: Union[xr.DataArray, str], get_min: bool = False,\n",
    "                        out_path: str = None, mask_raster: Union[xr.DataArray, str] = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Gets a max/min value from param:param_raster from the subset of all upslope cells for each cell in a FDR.\n",
    "        In TauDEM this is the \"Extreme Upslope Value\" function.\n",
    "        :param fdr: (xr.DataArray or str raster path) a TauDEM encoded D8 Flow Direction Raster (FDR).\n",
    "        :param param_raster: (xr.DataArray or str raster path) a raster with overlapping extent as param:fdr fromw which\n",
    "            extreme upslope values are pulled from (i.e., a DEM raster).\n",
    "        :param get_min: (bool, default=False) if True, the minimum param:param_raster value is returned from all upslope cells.\n",
    "        :param out_path: (str path, default=None) defines a path to save the output raster.\n",
    "        :param mask_raster: (xr.DataArray or str raster path) a dtype=int raster where cell values = 1 indicate areas to return values\n",
    "            for in the output (i.e., a stream mask to show the max elevation upslope of each part of a stream network).\n",
    "        :returns: (xarray.DataArray) the output raster with extreme upslope values as a DataArray object in memory.\n",
    "        \"\"\"\n",
    "        # make non-overlap cells\n",
    "        pass\n",
    "\n",
    "    # TauDEM: D8 Distance To Streams (includes decayGrid)\n",
    "    @abc.abstractmethod\n",
    "    def calculate_distance_to_stream(fdr: Union[xr.DataArray, str], mask_streams: Union[xr.DataArray, str],\n",
    "                             out_path: str = None):\n",
    "        \"\"\"\n",
    "        Create a raster where cell values represent the horizantal distance to the nearest stream ALONG the flow path.\n",
    "        :param fdr: (xr.DataArray or str raster path) a TauDEM encoded D8 Flow Direction Raster (FDR).\n",
    "        :param mask_streams: (xr.DataArray or str raster path) a binary raster where value=1 where for stream cells\n",
    "            as designated by meeting some flow accumulation threshold. Output of pyfunc:value_mask(thresh=int/float).\n",
    "        :param out_path: (str path, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray) a raster with cell value equal to the horizantal length along the flow path to the\n",
    "            the nearest stream cell.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # no TauDEM but does not make sense to include in GeoSpatialEngineLite\n",
    "    @abc.abstractmethod\n",
    "    def decay_raster(distance_to_stream_raster: Union[xr.DataArray, str], decay_constant: Union[float, int] = 2,\n",
    "                    out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Creates a decay weight raster based on distance to stream and a decay factor. The output raster\n",
    "            has values ranging from 0 (total decay) to 1 (no decay) and is intended to be used in pyfunc:decay_accumulation().\n",
    "            Note: output cell value: np.exp((-1 * distance_to_stream_raster * cell_size) / (cell_size ** decay_constant))`\n",
    "        :param distance_to_stream_raster: (xr.DataArray or str raster path) a raster with cell value equal to the flow path to the\n",
    "            the nearest stream cell. This raster is output from pyfunc:calculate_dsit2stream().\n",
    "        :param decay_constant: (float or int) the decay constant in the decay formula.\n",
    "            Set k to 2 for \"moderate\" decay; greater than 2 for slower decay; or less than 2 for faster decay.\n",
    "        :param out_path: (str path, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray) the output decay weighting raster as an xarray DataArray.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    # TauDEM: D-Infinity Decaying Accumulation\n",
    "    @abc.abstractmethod\n",
    "    def decay_accumulation(dinf_fdr: Union[xr.DataArray, str], decay_raster: Union[xr.DataArray, str],\n",
    "                           param_raster: Union[xr.DataArray, str] = None, out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Create a decayed accumulation raster from a D-Infinity FDR.\n",
    "        In TauDEM this is \"D-Infinity Decaying Accumulation\" function.\n",
    "        :param dinf_fdr: (xr.DataArray or str raster path) a D-Infinity Flow Direction Raster (FDR).\n",
    "        :param decay_raster: (xr.DataArray or str raster path) a distance_to_stream based decay raster (dtype=float, values 0-1).\n",
    "            Note: this is the output of pyfunc:make_decay_raster().\n",
    "        :param param_raster: (xr.DataArray or str raster path, default=None) a raster to accumulate.\n",
    "            if None, this function produces a D-Infinity decayed FAC.\n",
    "        :param out_path: (str path, default=None) defines a path to save the output raster.\n",
    "        :returns: (xr.DataArray) the output decayed accumulation raster as an xarray DataArray.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8024366-7522-4e0b-a54e-503b1b38a874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c19f278b-68f4-4331-b9ce-7339e2b44df9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Software architecture schematic (from meeting w/ Paul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2a3c6d-1bca-443e-95c6-620ef2729542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concrete implementation of GeoSpatialEngineLite.clip()\n",
      "Concrete implementation of GeoSpatialEngineLite.reproject()\n",
      "Concrete implementation of GeoSpatialEngineLite.resample()\n"
     ]
    }
   ],
   "source": [
    "########## base_classes.py #############\n",
    "# where ABCs are defines\n",
    "class GeoSpatialEngineLite_EXAMPLE(abc.ABC):\n",
    "    # ABC defining core functions\n",
    "    pass\n",
    "\n",
    "class GeoSpatialEngineFull_EXAMPLE(GeoSpatialEngineLite_EXAMPLE):\n",
    "    # ABC adding additional functions GeoSpatialEngineLite\n",
    "    pass\n",
    "\n",
    "class IOEngine_EXAMPLE(abc.ABC):\n",
    "    # ABC adding additional functions GeoSpatialEngineLite\n",
    "    pass\n",
    "\n",
    "########## engine.py #############\n",
    "# contains \"tech stack\" specific concrete implementations of the ABCs\n",
    "class PyShedSpatialEngineLite(GeoSpatialEngineLite_EXAMPLE):\n",
    "    # inherets from Lite\n",
    "    def clip(self):\n",
    "        print('Concrete implementation of GeoSpatialEngineLite.clip()')\n",
    "        pass\n",
    "    def reproject(self):\n",
    "        print('Concrete implementation of GeoSpatialEngineLite.reproject()')\n",
    "        pass\n",
    "    def resample(self):\n",
    "        print('Concrete implementation of GeoSpatialEngineLite.resample()')\n",
    "        pass\n",
    "\n",
    "class TauGDALSpatialEngineFull(GeoSpatialEngineFull_EXAMPLE):\n",
    "    # inherets from Full\n",
    "    def clip(self):\n",
    "        pass\n",
    "    def reproject(self):\n",
    "        pass\n",
    "    def resample(self):\n",
    "        pass\n",
    "\n",
    "class WhiteBoxSpatialEngineFull(GeoSpatialEngineFull_EXAMPLE):\n",
    "    def clip(self):\n",
    "        pass\n",
    "    def reproject(self):\n",
    "        pass\n",
    "    def resample(self):\n",
    "        pass\n",
    "        \n",
    "########## main.py ############# \n",
    "# where we run things\n",
    "pysheds_engine_lite = PyShedSpatialEngineLite()\n",
    "whitebox_engine = WhiteBoxSpatialEngineFull()\n",
    "\n",
    "########## tools.py ############# \n",
    "# where tools are provided (allowing for engine options)\n",
    "\n",
    "def resample_param(engine=pysheds_engine_lite) -> xr.DataArray:\n",
    "    engine.clip()\n",
    "    engine.reproject()\n",
    "    engine.resample()\n",
    "    pass\n",
    "\n",
    "# test - should print out 3 statements if engine=pysheds_engine_lite\n",
    "resample_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89894ffe-92ee-420a-9427-5b38803ee422",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Earlier stuff - Ignore for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6047dbd-5caf-4871-95ce-2854c0eb444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc  # for abstract base class design\n",
    "import os  # for file manipulations\n",
    "import xarray as xr  # for in memory raster manipulation\n",
    "import rioxarray  # for on disk manipulations (read/write)\n",
    "from typing import Union  # for better type-hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f3d336-5c6a-40b6-a777-479e0e6313e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186b4659-3007-4bc0-8b89-bfaa6f856ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a decorator to verify in and output paths\n",
    "def verify_path_dir(in_path: str, make_dir: bool = True) -> Union[bool, None]:\n",
    "    \"\"\"\n",
    "    Verifies that both an input path directories exist (for iterative use).\n",
    "    If not but the next higher level directory does exist (and make_dir=True), the directory is created.\n",
    "    :param in_path: str - a file path name.\n",
    "    :param make_dir: bool (defaults to True) - whether to make the directory is easily possible.\n",
    "    :returns: boolean - True is all input file directories exist or were created, false otherwise.\n",
    "    \"\"\"\n",
    "    status = False\n",
    "\n",
    "    # find if dir_path exists, or can be made\n",
    "    if isinstance(in_path, str):\n",
    "        dir_path = os.path.dirname(in_path)\n",
    "        if not os.path.exists(dir_path):\n",
    "            if make_dir:\n",
    "                if os.path.exists(os.path.dirname(dir_path)):\n",
    "                    try:\n",
    "                        print(f'Creating output directory: {dir_path}')\n",
    "                        os.makedirs(dir_path)\n",
    "                        status = True\n",
    "                    except Exception as e:\n",
    "                        print(f'Could not make {dir_path} due to the following exception {e}')\n",
    "                        return None\n",
    "        else:\n",
    "            status = True\n",
    "    else:\n",
    "        print(f'ERROR in :py:func:verify_path_dir() - in_path parameter is not a {type(in_path)} string!')\n",
    "        return None\n",
    "\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b534a55d-547a-456c-9744-043477b358ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# place to test out functions\n",
    "test_path = r'C:\\Users\\xrnogueira\\Documents\\FCPGtools\\try_this\\PR_test.ipynb'\n",
    "#  verify_path_dir(test_path, make_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc1739-e083-411b-8545-f4e308882745",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `ReadWriteEngine` - Input/Output Engine Class\n",
    "**Notes:**\n",
    "* The idea here is that all writing and reading to `xarray` can be done using class methods.\n",
    "* Come back and add ways to write raster attributes using [`rioxarray.to_raster()`](https://corteva.github.io/rioxarray/stable/rioxarray.html#rioxarray.raster_array.RasterArray.to_raster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da4a845-4182-438b-a034-000d38eef8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadWriteEngine(abc.ABC):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def open_raster(self, in_raster_path: str) -> Union[xr.DataArray, None]:\n",
    "        \"\"\"\n",
    "        Reads a raster file from path into an xarray DataArray.\n",
    "        :param in_raster_path: (str) a valid path to a georeferenced raster.\n",
    "        :return: ([xr.DataArray, None]) a DataArray object if a valid path is given,\n",
    "        or None if in_raster_path does not exist.\n",
    "        \"\"\"\n",
    "        if os.path.exists(in_raster_path):\n",
    "            # use the rioxarray (via :param:engine) to open a .tif as a xr.DataArray\n",
    "            # this is an experimental technique? other option...xr.open_dataarray(in_raster_path, decode_coords='ALL', engine=\"rasterio\")\n",
    "            raster = rioxarray.open_rasterio(in_raster_path, parse_coordinates=True)\n",
    "            return raster\n",
    "\n",
    "        else:\n",
    "            print(f'ERROR: {in_raster_path} does not exist.')\n",
    "            return None\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_raster_info(self, in_raster: Union[str, xr.DataArray]) -> dict:\n",
    "        \"\"\"\n",
    "        Get raster information (used to inform geoprocessing parameters to match parameter grids to FDR)\n",
    "        :param in_raster: either a raster path string or a DataArray\n",
    "        :returns: a dictionary with key raster attributes\n",
    "        \"\"\"\n",
    "        return dict\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def write_raster(self, in_raster: xr.DataArray, out_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Reads a raster file from path into an xarray DataArray.\n",
    "        :param in_raster: (xr.DataArray) a valid path to a georeferenced raster.\n",
    "        :param out_path: (str) a .tif path to write the raster to.\n",
    "        :return: (str) out_path that the raster was writted to (if successful).\n",
    "        \"\"\"\n",
    "        # check if the output directory exists\n",
    "        out_dir = os.dirname(out_path)\n",
    "        if os.path.exists(out_dir):\n",
    "            pass\n",
    "\n",
    "        # if the output directory does not exist, make it (if we can find the higher level directory)\n",
    "        elif os.path.exists(os.dirname(out_dir)):\n",
    "            os.makedirs(out_dir)\n",
    "            pass\n",
    "\n",
    "        # if we can't find a place to make the output directory, return an error\n",
    "        else:\n",
    "            return print(f'ERROR: Directory {os.dirname(out_dir)} does not exist and/or cannot be made.')\n",
    "\n",
    "        # export the DataArry to a GeoTIFF raster (add tags or kwags later?)\n",
    "        try:\n",
    "            in_raster.to_raster(out_path, driver='GTiff', compute=True)\n",
    "            return out_path\n",
    "        except Exception as e:\n",
    "            return print(f'Could not save raster to {out_path}\\n Exception: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f95986-e577-4c7d-804b-67578e2bc939",
   "metadata": {
    "tags": []
   },
   "source": [
    "## `GeospatialEngineFull` Class - uses `xarray`\n",
    "**Notes:**\n",
    "* I am starting with defining the complete geospatial engine, then we can consider which aspects can be pulled in to `GeoSpatialEngineLite`.\n",
    "    * There will be duplicate techniques to do the same thing between pysheds vs taudem as well as GDAL vs xarray.\n",
    "* **Choose between an `xarray.DataArray` vs `xarray.Dataset` implementation!**\n",
    "* The idea here is that `xarray` data comes in, and `xarray` data comes out! **All writing and reading is stored in the `IOEngine` class.*\n",
    "\n",
    "**Class methods:**\n",
    "* Get a parameter grid aligned (splits `resampleParam()` into 3 functions):\n",
    "    * `reproject_raster()` - uses [`rioxarray.reproject_match()`](https://corteva.github.io/rioxarray/stable/rioxarray.html?highlight=write_crs#rioxarray.raster_array.RasterArray.reproject_match) OR [`rioxarray.reproject()`](https://corteva.github.io/rioxarray/stable/rioxarray.html#rioxarray.raster_Dataset.RasterDataset.reproject) to reproject a raster.\n",
    "    * `requery_point()` - uses \n",
    "    * `clip_raster()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f716319a-30ce-4a4f-86fd-593fc31138c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSpatialEngineLite(abc.ABC):\n",
    "\n",
    "    # NOTE: On second thought would this work better as a function?\n",
    "    class GDALWarp():\n",
    "        \"\"\"\n",
    "        GDALWarp wrapper to align a raster (via reprojection and/or resampling and/or clipping) with another raster.\n",
    "        Alternatively, the GDALWarp command can be customized beyond defeault behavior pythonically.\n",
    "        Use GDALWarp.execute() to execute on the command line via subprocesses.\n",
    "        If the existing pamarmeters don't achieve the use case, one can pass in a custom gdal command via .execute(custom_cmd:str)\n",
    "        \"\"\"\n",
    "\n",
    "        def add_resample(self, add: bool, xsize: Union[int, float], ysize: Union[int, float] = None) -> str:\n",
    "            if add:\n",
    "                if ysize is None:\n",
    "                    ysize = xsize\n",
    "                return f' -tr {xsize} {ysize}'\n",
    "            else:\n",
    "                return ''\n",
    "\n",
    "        def add_reproject(self, add: bool, fdrcrs: str) -> str:\n",
    "            if add:\n",
    "                return f' -t_srs {fdrcrs}'\n",
    "            else:\n",
    "                return ''\n",
    "\n",
    "        def add_clip(self, add: bool, xminmax: tuple, yminmax: tuple) -> str:\n",
    "            if add:\n",
    "                return f' -te {xminmax[0]} {yminmax[0]} {xminmax[1]} {yminmax[1]}'\n",
    "            else:\n",
    "                return ''\n",
    "\n",
    "        def execute(self, in_raster: str, out_raster: str, match_raster: str, optimize_cores: bool = True,\n",
    "                    reproject: bool = True, resample: bool = True, clip: bool = True,\n",
    "                    custom_cmd: str = None, new_dtype: str = None, new_cellsize: Union[float, int] = None,\n",
    "                    new_nodata: int = None, override_crs: str = None) -> str:\n",
    "            \"\"\"\n",
    "            Executes GDALWarp cmd\n",
    "            \"\"\"\n",
    "\n",
    "            # get params from raster info or override\n",
    "            # mock params...\n",
    "            cores, resample_method,  nodata, dtype, in_raster, out_raster = [1, 'bilinear', -1, 'int8', 'test_in.tif', 'test_out.tif']\n",
    "\n",
    "            # build end ofthe command\n",
    "            end_str = ' -co \"PROFILE=GeoTIFF\" -co \"TILED=YES\" -co \"SPARSE_OK=TRUE\" -co \"COMPRESS=LZW\" -co' \\\n",
    "                f' \"ZLEVEL=9\" -co \"NUM_THREADS={cores}\" -co \"BIGTIFF=IF_SAFER\" -r {resample_method} -dstnodata ' \\\n",
    "                f'{nodata} -ot {dtype} {in_raster} {out_raster}'\n",
    "\n",
    "            # add each warp command\n",
    "            resample_str = self.add_resample(bool(resample), 999, 999)\n",
    "            project_str = self.add_reproject(bool(reproject), fdrcrs='TESTCRS')\n",
    "            clip_str = self.add_clip(bool(clip), xminmax=(0, 9), yminmax=(0, 9))\n",
    "\n",
    "            # build final parameter -  then execute!\n",
    "            gdal_cmd = 'gdalwarp -overwrite' + resample_str + project_str + clip_str + end_str\n",
    "\n",
    "            return gdal_cmd\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def recode_d8_fdr(self) -> str:\n",
    "        \"\"\"\n",
    "        Recode a 8 directional Flow Direction Raster (FDR). Default is ESRI-TauDEM.\n",
    "        :param in_raster:\n",
    "        :param recode_dict: (optional, dict) an 8 item dictionary like {2: 4, 3: 6, ...}\n",
    "        that allows for custom raster recoding.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27836c36-5faf-4e4d-b878-03fa8f32eedd",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (1774815577.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [12], line 13\u001b[1;36m\u001b[0m\n\u001b[1;33m    def clip(engine='gdal'):\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "in_test = r'test_in.tif'\n",
    "out_test = r'test_out.tif'\n",
    "match_test = r'test_match.tif'\n",
    "\n",
    "engine = GeoSpatialEngineLite.GDALWarp()\n",
    "\n",
    "engine.execute(in_test, out_test, match_test)\n",
    "\n",
    "# see if we need to get \"\" around some cmd keywords?\n",
    "\n",
    "# Notes:\n",
    "# resample, reproject, clip could be functions in the GeoSpatialEngine\n",
    "def clip(engine='gdal'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca8021-1bb8-4805-8d62-a9d054c4b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSpatialEngineFull(abc.ABC):\n",
    "\n",
    "    # define basic raster functions to prep parameter grids W/O GDAL\n",
    "    @abc.abstractmethod\n",
    "    def reproject_raster(self, in_raster: Union[str, xr.DataArray],\n",
    "                         out_path: str = None) -> xr.DataArray:\n",
    "        \"\"\"\n",
    "        Reproject a raster using GDAL warp\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def requery_point(self, in_raster: Union[str, xr.DataArray],\n",
    "                        out_path: str = None) -> xr.DataArray:\n",
    "    \"\"\"\n",
    "    v1 - use GDAL warp\n",
    "    :returns: xarray DataArray resampled\n",
    "    \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def clip_raster(self, in_raster: Union[str, xr.DataArray],\n",
    "                    out_path: str = None) -> xr.DataArray:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e317b-0c54-4178-addd-9cbeddebd1ac",
   "metadata": {},
   "source": [
    "## Tools/stand-alone functions\n",
    "* `requires_full_engine()` - a decorator function that verifies if a given function is available in the engine being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd455e-1cfd-4848-baab-2288f184b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def requires_full_engine(func: callable, *args, **kwargs) -> callable:\n",
    "    \"\"\"\n",
    "    A decorator to check if the full engine is required\n",
    "    \"\"\"\n",
    "    def full_engine_function(engine, *args, **kwargs) -> any:\n",
    "        if not isinstance(engine, FullEngine):\n",
    "            raise ValueError(f'Invalid engine type. Function {func.__name__} requires FullEngine')\n",
    "        return func(engine, *args, **kwargs)\n",
    "    return full_engine_function\n",
    "\n",
    "\n",
    "def get_cores() -> int:\n",
    "    \"\"\"\n",
    "    Finds the # of cores available for multiprocessing\n",
    "    \"\"\"\n",
    "    return int"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
