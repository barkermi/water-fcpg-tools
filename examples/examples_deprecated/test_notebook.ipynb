{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCPG Test Notebook\n",
    "\n",
    "This notebook facilitates testing the the core functionality of the FCPG tools. This steps through providing input data, converting ESRI flow directions to TauDEM flow direction, resampling and reprojecting input data, generating upstream FCPGs, creating a dictionary to cascade values from upstream to downstream hydrologic units, updating downstream parameter grids, accumulating updated grids, and making FCPGs corrected for an upstream area. The last section verifies the handling of no data values if that is desired by the user.\n",
    "\n",
    "This notebook reads data from `./test_data` and writes data to `./test_output`. `./test_output` can be discarded after testing is complete.\n",
    "\n",
    "Input and output grids can be examined in either ArcGIS or QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import src.fcpgtools.tools_deprecated as fc\n",
    "import os\n",
    "import rasterio as rs\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Verbose output\n",
    "verbose = True\n",
    "\n",
    "\n",
    "def plot(fl, cmap='Blues'):\n",
    "    \"\"\"\n",
    "    Helper plotter function.\n",
    "    \"\"\"\n",
    "    src = rs.open(fl)\n",
    "    tmp = src.read(1)\n",
    "    try:\n",
    "        tmp[tmp == src.nodata] = np.NaN\n",
    "    except Exception:\n",
    "        pass\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(tmp, cmap = cmap)\n",
    "\n",
    "\n",
    "#print('FCPGtools version %s loaded from %s' % (fc.__version__, fc.__path__[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# upstream area FDR grid\n",
    "upstreamFDR = os.path.join('.', 'test_data', 'validation_upstream_fdr.tif')\n",
    "\n",
    "# downstream area FDR grid\n",
    "downstreamFDR = os.path.join('.', 'test_data', 'validation_downstream_fdr.tif')\n",
    "\n",
    "# upstream WBD subset to test cascading parameters\n",
    "#upstreamWBD = gpd.read_file(os.path.join('.', 'test_data, upstream_wbd.shp'))\n",
    "\n",
    "# parameter datasets\n",
    "P = os.path.join('.', 'test_data', 'validation_daymet_an_P_2017.tif')  # daymet annual P for 2017\n",
    "LC = os.path.join('.', 'test_data', 'NALCMS_2015.tif')  # North America Land Cover 2015\n",
    "\n",
    "testFolder = os.path.join('.', 'test_output')  # folder to store outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RasterioIOError",
     "evalue": ".\\test_data\\validation_upstream_fdr.tif: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32mrasterio\\_base.pyx:260\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\_shim.pyx:78\u001b[0m, in \u001b[0;36mrasterio._shim.open_dataset\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mrasterio\\_err.pyx:215\u001b[0m, in \u001b[0;36mrasterio._err.exc_wrap_pointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCPLE_OpenFailedError\u001b[0m: .\\test_data\\validation_upstream_fdr.tif: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRasterioIOError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# reproject the WBD to the grid CRS\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupstreamFDR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m dstCRS \u001b[38;5;241m=\u001b[39m tmp\u001b[38;5;241m.\u001b[39mcrs\u001b[38;5;241m.\u001b[39mto_proj4()\n\u001b[0;32m      5\u001b[0m upstreamWBD\u001b[38;5;241m.\u001b[39mto_crs(crs\u001b[38;5;241m=\u001b[39mdstCRS, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\fcpgtools\\lib\\site-packages\\rasterio\\env.py:435\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    432\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\fcpgtools\\lib\\site-packages\\rasterio\\__init__.py:207\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Create dataset instances and pass the given env, which will\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# be taken over by the dataset's context manager if it is not\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m# None.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 207\u001b[0m     s \u001b[38;5;241m=\u001b[39m DatasetReader(path, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    209\u001b[0m     s \u001b[38;5;241m=\u001b[39m get_writer_for_path(path, driver\u001b[38;5;241m=\u001b[39mdriver)(\n\u001b[0;32m    210\u001b[0m         path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    211\u001b[0m     )\n",
      "File \u001b[1;32mrasterio\\_base.pyx:262\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mRasterioIOError\u001b[0m: .\\test_data\\validation_upstream_fdr.tif: No such file or directory"
     ]
    }
   ],
   "source": [
    "# reproject the WBD to the grid CRS\n",
    "tmp = rs.open(upstreamFDR)\n",
    "dstCRS = tmp.crs.to_proj4()\n",
    "\n",
    "upstreamWBD.to_crs(crs=dstCRS, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make test output location if it doesn't exist, this directory can be deleted later\n",
    "if os.path.exists(testFolder) is False:\n",
    "    os.mkdir(testFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert ESRI FDR to TauDEM FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define output paths\n",
    "upstreamFDRTau = os.path.join(testFolder, 'upstreamFDRtau.tif')\n",
    "downstreamFDRTau = os.path.join(testFolder, 'downstreamFDRtau.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# reclassify ESRI drainage directions to TauDEM\n",
    "fc.tauDrainDir(upstreamFDR, upstreamFDRTau, verbose=verbose)\n",
    "fc.tauDrainDir(downstreamFDR, downstreamFDRTau, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample Daymet and Land Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# define output paths\n",
    "Pupstream = os.path.join(testFolder, 'Pup.tif')\n",
    "Pdownstream = os.path.join(testFolder, 'Pdwn.tif')\n",
    "LCupstream = os.path.join(testFolder, 'LCup.tif')\n",
    "LCdownstream = os.path.join(testFolder, 'LCdwn.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "rs.open(r'.\\test_output\\upstreamFDRtau.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# resample and crop daymet (upstream then downstream)\n",
    "fc.resampleParam(P, upstreamFDRTau, Pupstream, forceProj=True, verbose=verbose)\n",
    "fc.resampleParam(P, downstreamFDRTau, Pdownstream, forceProj=True, verbose=verbose)\n",
    "\n",
    "# resanoke LC raster (upstream then downstream)\n",
    "fc.resampleParam(LC, upstreamFDRTau, LCupstream, forceProj=True,\n",
    "                 verbose=verbose, resampleMethod='near')\n",
    "fc.resampleParam(LC, downstreamFDRTau, LCdownstream, forceProj=True,\n",
    "                 verbose=verbose, resampleMethod='near')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarize Land Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "usLCbinary = fc.cat2bin(LCupstream, testFolder, verbose=verbose)\n",
    "dsLCbinary = fc.cat2bin(LCdownstream, testFolder, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulate the Upstream Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create path for, and the output for, a FAC grid\n",
    "upstreamFAC = os.path.join(testFolder, 'upstreamFAC.tif')\n",
    "\n",
    "fc.tauFlowAccum(upstreamFDRTau, upstreamFAC, cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot(upstreamFAC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration of Multiple Pour Points\n",
    "\n",
    "The following is a demonstration of the workflow for HUC4 geospatial tiles (NHD High-Res). The update dictionary produced here is not used after this Section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "upstreamWBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# get up- and  down- stream HUC4 basins IDs (HUC4 and ToHUC4 are the new columns)\n",
    "pourBasins = fc.makePourBasins(upstreamWBD, '1407', '1501')\n",
    "pourBasins.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# find pourpoints using the basin shapefile, FAC, and TauDEM FDR.\n",
    "pourPts = fc.findPourPoints(pourBasins, upstreamFAC, upstreamFDRTau, plotBasins=True)\n",
    "print(f'N={len(pourPts)} were found with the following XYZ coorindates: \\n{pourPts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create an initial dictionary for the region 14 to 15 cascade\n",
    "updateDictFl = os.path.join(testFolder, 'HUC1407_update.json')\n",
    "upHUC = '1407'\n",
    "\n",
    "# expand the pour points\n",
    "x, y, w = zip(*pourPts)\n",
    "ud = fc.createUpdateDict(x, y, w, upHUC, updateDictFl, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ud  # there are two pour points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Pour Point to Downstream Area\n",
    "Here we find the single pour point between region 14 and region 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# locate max FAC value\n",
    "x, y, d, w = fc.findLastFACFD(upstreamFAC, fl=upstreamFAC)\n",
    "\n",
    "# Get flow direction of above point\n",
    "x, y, f, w = fc.findLastFACFD(upstreamFAC, fl=upstreamFDRTau)\n",
    "print(x, y, d, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create an initial dictionary for the region 14 to 15 cascade\n",
    "updateDictFl = os.path.join(testFolder, 'HUC14_update.json')\n",
    "upHUC = '14'\n",
    "ud = fc.createUpdateDict([x], [y], [d], upHUC, updateDictFl, verbose=verbose)\n",
    "print(ud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCPG Upstream Daymet and Land Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# append the Daymet path to the land cover binary grids\n",
    "usLCbinary.append(Pupstream)\n",
    "print(usLCbinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "accumParams = fc.accumulateParam_batch(usLCbinary, upstreamFDRTau, testFolder,\n",
    "                                       cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "upstream_cpgs = fc.make_fcpg_batch(accumParams, upstreamFAC, testFolder, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Update Dictionary with FCPG Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Update the dictionary with values from the upstream accumulated parameters, this should probably be a v2 function...\n",
    "for fl in accumParams:  # iterate through the accumulated parameters\n",
    "    print(fl)\n",
    "    # Parse the file names into variable names...\n",
    "    varname = fl.split('/')[-1].split('up')[0]\n",
    "    if varname == 'LC':\n",
    "        mod = fl.split('/')[-1].split('up')[-1].split('accum')[0]\n",
    "        var = varname+mod\n",
    "    else:\n",
    "        var = varname\n",
    "\n",
    "    # Query accumualted raster for values\n",
    "    val = str(fc.queryPoint(x, y, fl))\n",
    "    ud = fc.updateDict(updateDictFl, '14', var, [val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "updateDictFl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cascade to Downstream Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "downstreamFACadj = os.path.join(testFolder, 'downstreamFACadj.tif')\n",
    "downstreamFACweight = os.path.join(testFolder, 'downstreamFACweight.tif')\n",
    "fc.adjustFAC(downstreamFDRTau, downstreamFACweight, updateDictFl, downstreamFDRTau,\n",
    "             downstreamFACadj, cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dsLCbinary.append(Pdownstream)  # add the precip into the downstream land cover files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# create updated, unaccumulated parameter grids for the downstream region\n",
    "adjDSparams = []\n",
    "\n",
    "# iterate through the accumulated parameters\n",
    "for fl, inGrid in zip(accumParams, dsLCbinary):\n",
    "    # Parse the file names into variable names...\n",
    "    varname = fl.split('/')[-1].split('up')[0]\n",
    "    if varname == 'LC':\n",
    "        mod = fl.split('/')[-1].split('up')[-1].split('accum')[0]\n",
    "        var = varname+mod\n",
    "    else:\n",
    "        var = varname\n",
    "\n",
    "    outfl = inGrid.split('.tif')[0]+'adj.tif'\n",
    "\n",
    "    fc.adjustParam(var, inGrid, updateDictFl, outfl, verbose=verbose)\n",
    "    adjDSparams.append(outfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# accumulate the downstream parameter grids\n",
    "DSaccum = fc.accumulateParam_batch(adjDSparams, downstreamFDRTau, testFolder,\n",
    "                                   cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# accumulate the downstream area\n",
    "dsFCPG = fc.make_fcpg_batch(DSaccum, downstreamFACadj, testFolder, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert NoData values into Daymet and Verify FCPG NoData Behavior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with rs.open(upstreamFDR) as src:\n",
    "    fdr = src.read(1)\n",
    "    fdr[fdr == src.nodata] = 0\n",
    "    fdr[fdr != 0] = 1\n",
    "    mask = fdr.astype(np.uint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# make row,col vectors of where to insert nodata values\n",
    "size = 1000  # number of no data values to insert\n",
    "\n",
    "# get locations of all points within the watershed\n",
    "idCol, idRow = np.where(mask == 1)\n",
    "cols = np.random.choice(idCol, size=size, replace=False)\n",
    "rows = np.random.choice(idRow, size=size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# output file name\n",
    "PupstreamNoData = os.path.join(testFolder, 'PupNoData.tif')\n",
    "\n",
    "# open source\n",
    "with rs.open(Pupstream) as src:\n",
    "    meta = src.meta\n",
    "    noData = src.nodata\n",
    "    P = src.read(1)\n",
    "\n",
    "P[cols, rows] = noData  # insert nodata values\n",
    "\n",
    "# write out updated P grid\n",
    "with rs.open(PupstreamNoData, 'w', **meta) as dst:\n",
    "    dst.write(P, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# accumualte the P raster with no data values added and produce the noData grids\n",
    "\n",
    "accumRast = os.path.join(testFolder, 'PupNoData_accum.tif')\n",
    "outNoDataAccum = os.path.join(testFolder, 'PupNoData_accumNoData.tif')\n",
    "outNoData = os.path.join(testFolder, 'PupNodataRast.tif')\n",
    "outNoDataZero = os.path.join(testFolder, 'PupNoDataZero.tif')\n",
    "\n",
    "fc.accumulateParam(PupstreamNoData, upstreamFDRTau, accumRast,\n",
    "                   outNoDataRast = outNoData, outNoDataAccum=outNoDataAccum,\n",
    "                   zeroNoDataRast = outNoDataZero, cores=4, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# make a FCPG accounting for noData\n",
    "outRast = os.path.join(testFolder, 'Pup_FCPG_noData.tif')\n",
    "\n",
    "fc.make_fcpg(accumRast, upstreamFAC, outRast, noDataRast=outNoDataAccum, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decay FCPG\n",
    "\n",
    "Produce a FCPG where values are decayed based on their distance to a stream, this can be useful for producing FCPGs with more localized values rather than basin-average values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# D-infinity flow direction raster\n",
    "upstreamFDRTauDinf = os.path.join(testFolder, 'upstreamFDRDinf.tif')\n",
    "\n",
    "# convert D8 flow directions to D-inf flow directions\n",
    "fc.d8todinfinity(upstreamFDRTau, upstreamFDRTauDinf, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "streamDistRast = os.path.join(testFolder, 'upstreamDist2Stream.tif')  # distance to stream raster\n",
    "streamRast = os.path.join(testFolder, 'upstreamSTR900.tif')  # stream raster\n",
    "fc.makeStreams(upstreamFAC, streamRast, verbose = verbose)\n",
    "\n",
    "# compute distance to streams, use 900 cells as accumulation threshold\n",
    "fc.dist2stream(upstreamFDRTau, upstreamFAC, 900, streamDistRast, cores = 4, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "decayRast = os.path.join(testFolder, 'upstreamDecay.tif')\n",
    "k = 4  # decay coefficient\n",
    "fc.makeDecayGrid(streamDistRast, k, decayRast, verbose = verbose)\n",
    "plot(decayRast, cmap = 'Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "decayFAC = os.path.join(testFolder, 'decayAccum.tif')  # decay accumulation grid\n",
    "decayParam = os.path.join(testFolder, 'decayP.tif')  # decay parameter accumulation grid\n",
    "\n",
    "# perform the parameter decay accumulation\n",
    "fc.decayAccum(upstreamFDRTauDinf, decayRast, decayParam,  \n",
    "              paramRast = Pupstream, cores = 4, verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "decayFCPG = os.path.join(testFolder, 'decayFCPG.tif')\n",
    "\n",
    "# Mask out pixels not on streamlines\n",
    "fc.maskStreams(decayParam, streamRast, decayFCPG, verbose = verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e9ed1bec11c70bedbd5347b4cbfe39ec6f6840fe8bfd487b3271e383f4325229"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
